<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>CAS Regulations for AI - Ex Machina</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="CAS Regulations for AI" />
<meta property="og:description" content="


The PM-EAC suggests that AI should be regulated as a complex adaptive system. While there is a lot to say about this approach, in its articulation, the paper fails to take into account many of the essential features of modern AI." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://rahulmatthan.github.io/14/02/2024/cas-regulations-for-ai/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-02-14T00:00:00+00:00" />
<meta property="article:modified_time" content="2024-02-14T00:00:00+00:00" />

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo logo--mixed">
		<a class="logo__link" href="/" title="Ex Machina" rel="home">
			<div class="logo__item logo__imagebox">
					<img class="logo__img" src="/images/exmachina.jpg">
				</div><div class="logo__item logo__text">
					<div class="logo__title">Ex Machina</div>
					<div class="logo__tagline">Law. Technology. Society.</div>
				</div>
		</a>
	</div>
		
<nav class="menu">
	<button class="menu__btn" aria-haspopup="true" aria-expanded="false" tabindex="0">
		<span class="menu__btn-title" tabindex="-1">Menu</span>
	</button>
	<ul class="menu__list">
		<li class="menu__item">
			<a class="menu__link" href="/index/">
				
				<span class="menu__text">Index</span>
				
			</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/topics/">
				
				<span class="menu__text">Topics</span>
				
			</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/books/">
				<i class='fa fa-road'></i>
				<span class="menu__text">Books</span>
				
			</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/podcast/">
				<i class='fa fa-road'></i>
				<span class="menu__text">Podcast</span>
				
			</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/about/">
				<i class='fa fa-road'></i>
				<span class="menu__text">About</span>
				
			</a>
		</li>
	</ul>
</nav>

	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">CAS Regulations for AI</h1>
			<div class="post__meta meta">
<div class="meta__item-datetime meta__item">
	<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class="meta__text" datetime="2024-02-14T00:00:00Z">February 14, 2024</time></div></div>
		</header>
		<div class="content post__content clearfix">
			<figure><img src="/images/ey.jpg" width="auto"/>
</figure>

<p><em>The PM-EAC suggests that AI should be regulated as a complex adaptive system. While there is a lot to say about this approach, in its articulation, the paper fails to take into account many of the essential features of modern AI.</em></p>
<p><em>This article was first published in The Mint. You can read the original at <a href="https://www.livemint.com/opinion/online-views/a-good-way-to-regulate-ai-is-to-think-of-it-as-a-complex-adaptive-system-11707837055204.html"><em>this link</em></a>.</em></p>
<hr>
<p>Last month, the Prime Minister’s Economic Advisory Council (PM-EAC) released a <a href="https://eacpm.gov.in/wp-content/uploads/2024/01/EACPM_AI_WP-1.pdf">paper</a> proposing a new approach to regulating Artificial Intelligence (AI). It argues that while our current approach of enacting reactionary regulations might work in a static, linear system with predictable risks, it is unlikely to work in the context of AI, which comprises emergent, non-linear systems. It argues that since AI is a dynamic network of diverse agents whose interactions generate emergent behaviours, we need to think of it as a complex adaptive system (CAS) and design regulations accordingly.</p>
<h3 id="regulating-cas">Regulating CAS</h3>
<p>We already have experience dealing with complex adaptive systems like <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1745-6622.2002.tb00448.x">stock markets</a>. The paper attempts to extract regulatory principles from those systems, so that we can apply them to AI. For instance, it suggests that we put in place <a href="https://opendatascience.com/how-to-use-guardrails-to-design-safe-and-trustworthy-ai/">guardrails</a> and partitions to define operational spaces within which AI can operate, so that, if needed, we can be sure it will not accidentally stray into potentially hazardous areas. It also calls for building <a href="https://www.nationalacademies.org/news/2022/04/ensuring-human-control-over-ai-infused-systems">manual overrides</a> and authorization choke-points directly into these AI systems, so that humans can effectively take control of operations where needed. It makes the case for “<a href="https://oecd.ai/en/dashboards/ai-principles/P7">transparency and explainability</a>,” so that there will always be public scrutiny of these systems. The PM-EAC paper also suggests that we ensure “distinct <a href="https://link.springer.com/article/10.1007/s00146-023-01635-y">accountability</a>,” so we can always identify the entity or individual responsible for any unintended consequence. Finally, the paper recommends that we put in place an AI regulator with the expertise and the mandate to recalibrate regulations on the fly to deal with the dynamic requirements of CAS regulation.</p>
<p>If nothing else, categorizing AI as a CAS is a refreshingly novel approach to finding solutions for a particularly challenging problem. AI policies tend to be knee-jerk responses to manifestations of harms resulting from the use of this technology, but regulators using this <a href="https://www.brookings.edu/articles/the-three-challenges-of-ai-regulation/">whack-a-mole approach</a> will constantly find themselves behind the curve. By taking a step back and thinking of the entire AI landscape as a CAS that displays emergent behaviour and is continuously and spontaneously evolving is an effective way to arrive at a workable long-term solution.</p>
<p>For that reason, I agree with the proposal to put in place a dedicated and <a href="https://www.weforum.org/agenda/2023/11/its-time-we-embrace-an-agile-approach-to-regulating-ai/">agile</a> expert regulatory body with the power to issue directions and amend regulations on-the-fly as and when required. If such a regulator is obliged to operate in accordance with a set of principles aligned with the democratic values of the country, I see this as no different from the principles-based regulation approach that I have called for in earlier <a href="https://exmachina.in/02/02/2021/principle-based-regulations/">articles</a> in this column.</p>
<h3 id="partitions-and-accountability">Partitions and Accountability</h3>
<p>That said, there is much that I disagree with in the paper, such as the idea of guardrails and partitions that it suggests. While the concept itself may be sound, given the way in which AI has already been built so far, this suggestion would be virtually impossible to implement. Much of AI development has been [modular](<a href="https://sapphireventures.com/blog/the-future-of-ai-infrastructure-is-becoming-modular/">https://sapphireventures.com/blog/the-future-of-ai-infrastructure-is-becoming-modular/</a>—particularly lower down the stack, with customization mainly taking place at higher levels.</p>
<p>As a consequence, for all intents and purposes, this is a ship that might have already sailed. While it is still possible to ‘[air-gap](<a href="https://www.howtogeek.com/687792/the-ultimate-defense-what-is-an-air-gapped-computer/">https://www.howtogeek.com/687792/the-ultimate-defense-what-is-an-air-gapped-computer/</a>’ some core systems—think of weapons, power grids, etc—doing so will force us to build them from scratch, and, as a result, forgo many of the benefits that could have come from building on top of what has already been developed.</p>
<p>This is also why the goal of ensuring “distinct accountability” might be impossible to achieve. Today, AI is designed to be <a href="https://www.clickworker.com/customer-blog/interoperability-and-the-future-of-machine-learning/">interoperable</a>, with access provided through application programming interfaces (APIs) designed for deep integration of AI into other digital products. Technologies like <a href="https://ifttt.com/">IFTTT</a> and <a href="https://zapier.com/">Zapier</a> take this interoperability even further by allowing do-it-yourself combinations of services without any need for coding expertise. All of which is to say that even though we are at the dawn of the AI age, it may already be impossible to pin distinct responsibility for AI outcomes on a single individual or entity.</p>
<h3 id="oversight-and-explainability">Oversight and Explainability</h3>
<p>I am just as sceptical of the paper’s blind insistence on human oversight and the need always to have <a href="https://levity.ai/blog/human-in-the-loop">humans in the loop</a>. One of the reasons why we moved to automation in the first place was to avoid <a href="https://www.psychologytoday.com/us/blog/thoughts-on-thinking/201809/12-common-biases-that-affect-how-we-make-everyday-decisions">biased human decision-makers</a>. Now that we have committed ourselves to this path and integrated machines into our workflows, we have reached a point where humans can no longer keep up. Our <a href="https://www.nature.com/articles/d41586-019-03847-z">poorer senses</a> and <a href="https://www.investopedia.com/financial-edge/0113/has-high-frequency-trading-ruined-the-stock-market-for-the-rest-of-us.aspx">slower reaction times</a> mean that we are <a href="https://theconversation.com/digital-diagnosis-intelligent-machines-do-a-better-job-than-humans-53116">no match for our machine counterparts</a>.</p>
<p>And then there is the demand for transparency and explainability. As I have argued before, whenever we insist on transparency, it is often in <a href="https://arxiv.org/pdf/2307.14239.pdf">exchange for performance</a>,  and while in certain circumstances—such as where human life and liberty are at stake—this might be appropriate, in others, it will not be. For instance, AI can analyse radiology images with far greater accuracy than humans. If this gives me a better chance at detecting a potentially fatal disease, I don’t see why I should give this up simply because we need algorithms to be explainable.</p>
<p>Using a CAS approach to formulate regulations for AI is indeed novel and refreshing as a way to solve a wicked problem. But we cannot blindly apply these regulatory principles to AI without a proper understanding of how it will impact operations in this important sector. Instead, we should work at adapting CAS principles so that we can achieve the desired outcomes.</p>
		</div>
		<footer class="post__footer">
			
<div class="post__tags tags clearfix">
	<svg class="tags__badge icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M32 19c0 1-1 2-1 2L21 31s-1 1-2 1-2-1-2-1L2 16c-1-1-1.4-2-1.4-2S0 12.5 0 11V3C0 1.5.8.8.8.8S1.5 0 3 0h8c1.5 0 3 .6 3 .6S15 1 16 2l15 15s1 1 1 2zM7 10a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"/></svg>
	<ul class="tags__list">
		<li class="tags__item">
			<a class="tags__link btn" href="/tags/artificial-intelligence/" rel="tag">artificial intelligence</a>
		</li>
	</ul>
</div>
		</footer>
	</article>
</main>

<div class="authorbox clearfix">
	<figure class="authorbox__avatar">
		<img alt="Rahul Matthan avatar" src="/images/avatar.png" class="avatar" height="90" width="90">
	</figure>
	<div class="authorbox__header">
		<span class="authorbox__name">About Rahul Matthan</span>
	</div>
	<div class="authorbox__description">
		Rahul Matthan is a lawyer who works at the intersection of law, technology and society.
	</div>
</div>

<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/31/01/2024/liars-dividend/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Liars Dividend</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/21/02/2024/virtual-power-plants/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Virtual Power Plants</p>
		</a>
	</div>
</nav>


			</div>
			<aside class="sidebar">
</aside>
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 Ex Machina.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>