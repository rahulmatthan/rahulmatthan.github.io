---
title: "Colluding Algorithms"
date: "2017-02-08"
tags: ["Competition"]
widgets: 
- "categories"
---

*Auto rickshaw drivers often charge more than the metered fare in response to market dynamics, similar to surge pricing in ride-hailing apps. This raises competition law concerns, as algorithm-driven pricing could lead to unintentional collusion, setting higher equilibrium prices. The challenge for regulators is to adapt antitrust laws to address potential collusion by autonomous algorithms, which can independently develop strategies for profit maximization, including tacit collusion, without overt intent or agreement.*
<!--more-->
*This article was first published in The Mint. You can read the original at [this link](https://www.livemint.com/Opinion/J2kisMEcqSm9ER9ZumddRL/Colluding-algorithms.html).*

---

Auto rickshaw drivers are notorious for taking advantage of a situation. Even though they are required by law to charge by the meter, chances are that if it’s raining, they will demand much more than the metered fare. As much as we might detest this behaviour, this is merely a response to market dynamics—an instinctive appreciation of the fact that you will pay more to get out of the rain.

Thanks to the new urban transportation options that ride-hailing apps offer us, we are less concerned today about auto rickshaw drivers and their predatory practices. But if you look at it more closely, things are not that different in today’s app-driven taxi market. After all, what is surge-pricing other than algorithmically determined price-fixing that is responsive to supply and demand.

As a matter of fact, some people argue that fares that have been dynamically determined by algorithms have a negative effect on competition. While the decision of an auto driver only affects your ability to ride in his vehicle, surge pricing sets the price for all drivers in a location, effectively establishing a horizontal price agreement in that region. And as more freelance cabbies sign up to the service, the impact of such agreements will be exacerbated. While these algorithms are designed to discover the price established by market forces, since the code itself is proprietary, detractors argue that it will be impossible to determine whether these algorithms are actually coordinating price increases above the market.

This is the latest frontier of competition law—the cutting edge where laws, for the most part, are genuinely struggling to keep pace with developments in technology. Where regulators have no idea what has to be done to make human-centric antitrust laws apply effectively to bot-intermediated transactions.

In 2015, the US Department of Justice secured its first prosecution against an algorithmic cartel. David Topkins, a seller of posters on Amazon’s marketplace, used price-fixing algorithms to establish collusive, non-competitive prices at which he and his co-conspirators could sell products online. This was a relatively easy case to prosecute as there was ample evidence of agreement between the conspirators to collude. The real challenge lies in prosecuting transactions where no such evidence exists.

It is possible for a seller, independently and without collusion with others, to configure his algorithm to adopt a strategy of following price increases. If all other sellers similarly program their algorithms to follow the same logic, the price that ultimately gets fixed will most likely be at an equilibrium higher than what would otherwise have been arrived at competitively. There is nothing illegal about designing algorithms to respond to market dynamics. If, as a result of this, they arrive at a price that is higher than the market, they will have done so without any overt intent to collude. However, when viewed as a whole, it is likely that the interplay between these algorithms would be held to have affected competition. However, under the current structure of our laws, in the absence of proof of actual collusion, regulators will be hard-pressed to secure a prosecution.

Things get even more complex when autonomous algorithms are thrown into the mix. Machine-learning algorithms are designed to operate without humans programming the logic they use to arrive at their decisions. All they need is training data and details of the boundary conditions within which they are allowed to operate in order to be able to figure out, all on their own, how best to achieve the required results. We’ve begun to see these algorithms in the world around us—from IBM’s Watson and Google’s AlphaGo, to Siri, Alexa and various other automated personal assistants.

If these machine-learning algorithms are turned loose in an e-commerce marketplace with instructions to maximize profit within boundary constraints that prohibit price-fixing and market-sharing, they will develop an optimal strategy to achieve those results.

Since one of the ways of achieving higher profits is through successful collusion, chances are that these algorithms will figure out a way to collude with other algorithms driven by similar motivations, in a manner that does not violate their boundary constraints. And since not even the programmers who design these algorithms have any clue how these programs make these decisions, antitrust authorities will have no way to prosecute given that they will have no useful evidence of collusion.

In this new world of colluding algorithms, the concepts of “agreement" and “intent" that we used to rely upon to define anti-competitive behaviour will have little relevance. Instead, policymakers will need to figure out how to automatically audit pricing algorithms and where necessary introduce automated checks and balances directly into their design so that they can monitor the interplay of these algorithms and intervene before it is too late.

