<!doctype html><html class=no-js lang=en><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><title>Privacy Self-Management - Ex Machina</title><script>(function(e,t){e[t]=e[t].replace("no-js","js")})(document.documentElement,"className")</script><meta name=description content><meta property="og:url" content="http://rahulmatthan.github.io/11/11/2021/privacy-self-management/"><meta property="og:site_name" content="Ex Machina"><meta property="og:title" content="Privacy Self-Management"><meta property="og:description" content="When there were limited uses to which data could be put, it was easy to evaluate the harms that could result from providing consent. Things are much more complex today so data protection regulations have tried to improve the quality of consent. This has resulted in the transparency paradox. If we can adopt consent templates we can give users appropriate autonomy."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2021-11-11T00:00:00+00:00"><meta property="article:modified_time" content="2021-11-11T00:00:00+00:00"><meta property="article:tag" content="Privacy"><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=dns-prefetch href=//fonts.googleapis.com><link rel=dns-prefetch href=//fonts.gstatic.com><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700"><link rel=stylesheet href=/css/style.css><link rel="shortcut icon" href=/favicon.ico></head><body class=body><div class="container container--outer"><header class=header><div class="container header__container"><div class="logo logo--mixed"><a class=logo__link href=/ title="Ex Machina" rel=home><div class="logo__item logo__imagebox"><img class=logo__img src=/images/exmachina.jpg></div><div class="logo__item logo__text"><div class=logo__title>Ex Machina</div><div class=logo__tagline>Law. Technology. Society.</div></div></a></div><nav class=menu><button class=menu__btn aria-haspopup=true aria-expanded=false tabindex=0>
<span class=menu__btn-title tabindex=-1>Menu</span></button><ul class=menu__list><li class=menu__item><a class=menu__link href=/index/><span class=menu__text>Index</span></a></li><li class=menu__item><a class=menu__link href=/topics/><span class=menu__text>Topics</span></a></li><li class=menu__item><a class=menu__link href=/books/><i class='fa fa-road'></i>
<span class=menu__text>Books</span></a></li><li class=menu__item><a class=menu__link href=/podcast/><i class='fa fa-road'></i>
<span class=menu__text>Podcast</span></a></li><li class=menu__item><a class=menu__link href=/about/><i class='fa fa-road'></i>
<span class=menu__text>About</span></a></li></ul></nav></div></header><div class="wrapper flex"><div class=primary><main class=main role=main><article class=post><header class=post__header><h1 class=post__title>Privacy Self-Management</h1><div class="post__meta meta"><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class=meta__text datetime=2021-11-11T00:00:00Z>November 11, 2021</time></div></div></header><div class="content post__content clearfix"><p><em>When there were limited uses to which data could be put, it was easy to evaluate the harms that could result from providing consent. Things are much more complex today so data protection regulations have tried to improve the quality of consent. This has resulted in the transparency paradox. If we can adopt consent templates we can give users appropriate autonomy.</em></p><p><em>This article was first published in The Mint. You can read the original at <a href=https://www.livemint.com/opinion/columns/the-transparency-paradox-of-privacy-based-on-consent-11636476597662.html>this link</a>.</em></p><hr><p>I ended <a href=/03/november/2021/calculated-communication/>last week’s article</a> with a quote from Byrne Hobart that called the act of communication a controlled violation of privacy. I thought this was an unusual perspective on the nature of personal communication, but it wasn’t until further reflection that I realized that if it were indeed true, it must mean that all social interactions are an exercise in trying to control the inadvertent disclosure of our private thoughts and beliefs.</p><p>To be clear, this is a relatively recent problem. When all our social engagements took place solely in the physical realm, even if our interactions revealed insights into our personal traits, they were only observable by the limited few with whom we engaged. Moreover, thanks to the fallibility of human memory, any inadvertent disclosures tended to be easily forgotten. Which is why we acted with less restraint, secure in the knowledge that the threat to privacy was minimal at best.</p><h3 id=control-over-data>Control over Data</h3><p>Now that almost all our social engagements are online, our interactions play out on a larger stage where nothing we say or upload is ever forgotten. Any hope of retaining anything close to the level of personal privacy we once enjoyed depends entirely on our ability to control what is done with our data. Which is why modern privacy law is so narrowly focused on ensuring that data subjects are able to retain control over their personal data.</p><p>In the early days of data protection, all one needed for such control to be exercised was to make sure that personal data was not used without consent. In those days, there were limited uses to which data could be put and it was easy to evaluate the possible harms that could result from providing consent. With the advent of big data, things have become much more complicated. The number of parties involved in the collection, dissemination and use of personal data has exploded, as have the present and future uses to which it can be put. This means that consent is no longer as effective as it once was as a mechanism of control.</p><h3 id=improving-consent>Improving Consent</h3><p>Most modern data protection regulations try and solve this problem by improving the quality of consent. They attempt to improve privacy decision-making by requiring data collectors to provide full details of the various uses to which data could be put, so that consent is only obtained after all relevant information has been considered.</p><p>Unfortunately, given the sheer scale at which data is used today, by the time each of the multiple entities to which data could be transmitted has been listed along with all details of the complicated multi-party data flows that would involve, our privacy policies were becoming so long and complex as to be effectively unintelligible. Realizing that notice requirements were creating impossibly complex privacy documents, regulators pivoted yet again, requiring that all details required under the law—what the data could be used for and the entities with which it will be shared —be presented in simple terms that laypersons could easily understand.</p><h3 id=transparency-paradox>Transparency Paradox</h3><p>Helen Nissenbaum refers to these internally inconsistent objectives as ‘<a href=https://nissenbaum.tech.cornell.edu/papers/BigDatasEndRun.pdf>the transparency paradox</a>’. Modern data businesses are so complex that it is simply not possible to anticipate all the consequences that could result from their data flows unless users are provided exhaustive information about the many ways in which they process data. Yet, when all that detail is transparently presented in a privacy policy, it results in documentation so long and complicated as to be beyond the capacity of even the most sophisticated among us to comprehend.</p><p>Many have argued that it is precisely because of the transparency paradox, and other similar failings of consent, that we need to come up with an alternative to our current ‘<a href=https://harvardlawreview.org/wp-content/uploads/pdfs/vol126_solove.pdf>self-management</a>’ approach to data protection. They argue for a more paternalistic approach to data protection, suggesting that since we cannot effectively make these decisions for ourselves, the regulator should intervene on our behalf, stipulating what data businesses should or should not do with our data.</p><p>In my view, this approach swings too far to the other extreme. Even if we are incapable of fully appreciating all the many ways in which data processing could affect our personal privacy, completely relinquishing all control over these decisions to a regulator denies us any choice whatsoever in the matter.</p><h3 id=middle-ground>Middle Ground</h3><p>As is often the case, the most effective solution would be to find a middle ground between those two extremes. People want to have some control over data decisions without having to micromanage every last aspect of it. This means that while regulation should define broad substantive rules around the collection and use of data, it should, at the same time, leave space for users to negotiate their own personal relationships with data businesses that reflects their own individual approach to privacy.</p><p>One way to achieve this would be to implement consent templates. These could be broad sector-specific frameworks that regulators can use to prescribe the contours of permissible data collection, processing and use. This will offer users the assurance that someone is watching out for their best interests in terms of the privacy consequences of providing consent.</p><p>When coupled with granular consent implemented using technological tools that allow users to choose what can be done with their data (with full knowledge of all the trade-offs implicit in each granular decision), users will also be able to retain an appropriate level of autonomy over their data decisions.</p></div><footer class=post__footer><div class="post__tags tags clearfix"><svg class="tags__badge icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M32 19c0 1-1 2-1 2L21 31s-1 1-2 1-2-1-2-1L2 16c-1-1-1.4-2-1.4-2S0 12.5.0 11V3C0 1.5.8.8.8.8S1.5.0 3 0h8c1.5.0 3 .6 3 .6S15 1 16 2l15 15s1 1 1 2zM7 10a3 3 0 100-6 3 3 0 000 6z"/></svg><ul class=tags__list><li class=tags__item><a class="tags__link btn" href=/tags/privacy/ rel=tag>Privacy</a></li></ul></div></footer></article></main><div class="authorbox clearfix"><figure class=authorbox__avatar><img alt="Rahul Matthan avatar" src=/images/avatar.png class=avatar height=90 width=90></figure><div class=authorbox__header><span class=authorbox__name>About Rahul Matthan</span></div><div class=authorbox__description>Rahul Matthan is a lawyer who works at the intersection of law, technology and society.</div></div><nav class="pager flex"><div class="pager__item pager__item--prev"><a class=pager__link href=/03/11/2021/calculated-communication/ rel=prev><span class=pager__subtitle>«&#8201;Previous</span><p class=pager__title>Calculated Communication</p></a></div><div class="pager__item pager__item--next"><a class=pager__link href=/17/11/2021/predicting-the-future/ rel=next><span class=pager__subtitle>Next&#8201;»</span><p class=pager__title>Predicting the Future</p></a></div></nav></div><aside class=sidebar></aside></div><footer class=footer><div class="container footer__container flex"><div class=footer__copyright>&copy; 2025 Ex Machina.
<span class=footer__copyright-credits>Generated with <a href=https://gohugo.io/ rel="nofollow noopener" target=_blank>Hugo</a> and <a href=https://github.com/Vimux/Mainroad/ rel="nofollow noopener" target=_blank>Mainroad</a> theme.</span></div></div></footer></div><script async defer src=/js/menu.js></script></body></html>