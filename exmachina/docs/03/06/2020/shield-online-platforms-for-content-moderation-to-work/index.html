<!doctype html><html class=no-js lang=en><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><title>Shield online platforms for content moderation to work - Ex Machina</title><script>(function(e,t){e[t]=e[t].replace("no-js","js")})(document.documentElement,"className")</script><meta name=description content><meta property="og:url" content="http://rahulmatthan.github.io/03/06/2020/shield-online-platforms-for-content-moderation-to-work/"><meta property="og:site_name" content="Ex Machina"><meta property="og:title" content="Shield online platforms for content moderation to work"><meta property="og:description" content="I believe the Indian government should introduce Good Samaritan protections in its new Intermediary Guidelines, prosecuting those who negligently allow violative content on their platforms. There is a need for a balanced approach that encourages responsible moderation without stifling free speech."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2020-06-03T00:00:00+00:00"><meta property="article:modified_time" content="2020-06-03T00:00:00+00:00"><meta property="article:tag" content="Content Moderation"><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=dns-prefetch href=//fonts.googleapis.com><link rel=dns-prefetch href=//fonts.gstatic.com><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700"><link rel=stylesheet href=/css/style.css><link rel="shortcut icon" href=/favicon.ico></head><body class=body><div class="container container--outer"><header class=header><div class="container header__container"><div class="logo logo--mixed"><a class=logo__link href=/ title="Ex Machina" rel=home><div class="logo__item logo__imagebox"><img class=logo__img src=/images/exmachina.jpg></div><div class="logo__item logo__text"><div class=logo__title>Ex Machina</div><div class=logo__tagline>Law. Technology. Society.</div></div></a></div><nav class=menu><button class=menu__btn aria-haspopup=true aria-expanded=false tabindex=0>
<span class=menu__btn-title tabindex=-1>Menu</span></button><ul class=menu__list><li class=menu__item><a class=menu__link href=/index/><span class=menu__text>Index</span></a></li><li class=menu__item><a class=menu__link href=/topics/><span class=menu__text>Topics</span></a></li><li class=menu__item><a class=menu__link href=/books/><i class='fa fa-road'></i>
<span class=menu__text>Books</span></a></li><li class=menu__item><a class=menu__link href=/podcast/><i class='fa fa-road'></i>
<span class=menu__text>Podcast</span></a></li><li class=menu__item><a class=menu__link href=/about/><i class='fa fa-road'></i>
<span class=menu__text>About</span></a></li></ul></nav></div></header><div class="wrapper flex"><div class=primary><main class=main role=main><article class=post><header class=post__header><h1 class=post__title>Shield online platforms for content moderation to work</h1><div class="post__meta meta"><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class=meta__text datetime=2020-06-03T00:00:00Z>June 03, 2020</time></div></div></header><div class="content post__content clearfix"><p><em>I believe the Indian government should introduce Good Samaritan protections in its new Intermediary Guidelines, prosecuting those who negligently allow violative content on their platforms. There is a need for a balanced approach that encourages responsible moderation without stifling free speech.</em></p><p><em>This article was first published in The Mint. You can read the original at <a href=https://www.livemint.com/opinion/columns/shield-online-platforms-for-content-moderation-to-work-11591116270685.html>this link</a>.</em></p><hr><p>Last week, President Donald Trump publicly reacted to the protests that followed the killing of George Floyd, with a tweet that ended with the words &ldquo;&mldr; when the looting starts, the shooting starts.&rdquo; Shortly thereafter, Twitter, for the first time in its history, decided to hide the Presidential tweet behind a warning label that said that his message glorified violence. This decision did not go down well with the Oval Office. Twitter had already fact-checked the President&rsquo;s allegations of voter fraud through mail-in ballots and it seemed as if Twitter was purposely denying the President of the United States his right to free speech.</p><p>The White House swiftly issued an <a href=https://www.whitehouse.gov/presidential-actions/executive-order-preventing-online-censorship/>Executive Order</a>, stating that [[social media]] companies had to be passive bulletin boards and could not actively restrict speech. If they were going to censor content they would be treated like content creators and made subject to the liabilities that content creators face. The Order went on to refer to Section 230(c) of the Communications Decency Act, 1996, from which intermediaries derive their immunity from prosecution, stating that the provision was not intended to give platforms the freedom to silence viewpoints they disliked.</p><p>Let me state upfront that I don&rsquo;t believe this interpretation is entirely correct. While sub-section (1) of Section 230(c) does say intermediaries will not be liable for content posted by users, sub-section (2) was specifically designed to allow Good Samaritan moderation of online content. Even in the early days of the internet, it was clear that regulators would not be able to moderate content without the assistance of private platforms. Sub-section (2) was supposed to make this possible giving intermediaries immunity from liability for actions they took in good faith to restrict access to unlawful material. It was believed that with this immunity, internet platforms would have the incentive they needed to moderate the content that flowed through their pipes.</p><p>As a matter of fact, things did not exactly work out as intended. Despite the broad protection from liability that Section 230(c) gave them, most internet companies chose to rely on sub-section (1) of that section, setting themselves up to operate as passive publishers of content. In several instances, websites have used this publishers&rsquo; immunity to establish businesses that, for all intents and purposes, actively encourage the posting of unlawful content. As a result, instances of hate speech, cyber-bullying, defamation and abuse have proliferated online.</p><p>Around the world, the concept of intermediary liability has largely avoided invoking the Good Samaritan direction that the original law seemed to present. In India, Section 79 of the Information Technology Act, 2000 offers intermediaries immunity from liability if they have neither initiated nor interfered with the transmission of the message. Not only does the section make no mention of good faith moderation, it implies that tampering with the transmission of content would mean that immunity is no longer available.</p><p>Little wonder, therefore, that intermediary liability jurisprudence in India has moved in an entirely different direction. Rather than encouraging intermediaries to moderate content in good faith, the judgment in <em>Shreya Singhal v. Union of India</em> made it clear that internet companies had no obligation to take down content unless they were expressly instructed to do so by a court order. While this meant internet companies could no longer be arm-twisted to take down content, it offered no protection for take-downs of unlawful content in good faith.</p><p>The events of the past week make it clear that the notion of intermediary liability is about to undergo a re-think. The Executive Order called on the Federal Communications Commission in the United States to review the interaction between the various sub-sections of Section 230(c) with a view to ensuring that those engaging in censorship were not able to avail protections granted to publishers. In the meantime, the Indian Government is about to push through new Intermediary Guidelines that require internet companies to deploy artificial intelligence tools to identify and filter illegal content. In both instances, Good Samaritan protections for moderation in good faith seems to have been given a pass.</p><p>While a review of intermediary liability was perhaps unavoidable, I don&rsquo;t believe the experience of the last two and a half decades is ground enough to discard the concept of Good Samaritan protections entirely. In a <a href="https://papers.ssrn.com/abstract=3532691.">recent paper</a> on Section 230 reform, Daniel Citron and Mary Anne Franks suggest that if we draft these provisions more explicitly we might be able to achieve a better result. For instance, rather than merely offering protection for Good Samaritan actions, the law should prosecute Bad Samaritans, targeting those who permit the publication of unlawful content for punishment. They also suggest imposing a reasonable standard of care so that we can reduce instances of abuse while allowing the internet to still flourish.</p><p>The Indian Government would do well to consider consider these suggestions in the new Intermediary Guidelines. After all, forcing intermediaries to use AI tools for moderation without giving them any good faith protections will not end well.</p></div><footer class=post__footer><div class="post__tags tags clearfix"><svg class="tags__badge icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M32 19c0 1-1 2-1 2L21 31s-1 1-2 1-2-1-2-1L2 16c-1-1-1.4-2-1.4-2S0 12.5.0 11V3C0 1.5.8.8.8.8S1.5.0 3 0h8c1.5.0 3 .6 3 .6S15 1 16 2l15 15s1 1 1 2zM7 10a3 3 0 100-6 3 3 0 000 6z"/></svg><ul class=tags__list><li class=tags__item><a class="tags__link btn" href=/tags/content-moderation/ rel=tag>Content Moderation</a></li></ul></div></footer></article></main><div class="authorbox clearfix"><figure class=authorbox__avatar><img alt="Rahul Matthan avatar" src=/images/avatar.png class=avatar height=90 width=90></figure><div class=authorbox__header><span class=authorbox__name>About Rahul Matthan</span></div><div class=authorbox__description>Rahul Matthan is a lawyer who works at the intersection of law, technology and society.</div></div><nav class="pager flex"><div class="pager__item pager__item--prev"><a class=pager__link href=/27/05/2020/an-opportunity-lost-for-an-internet-we-could-all-rely-on/ rel=prev><span class=pager__subtitle>«&#8201;Previous</span><p class=pager__title>An opportunity lost for an internet we could all rely on</p></a></div><div class="pager__item pager__item--next"><a class=pager__link href=/09/06/2020/online-dispute-resolution/ rel=next><span class=pager__subtitle>Next&#8201;»</span><p class=pager__title>Online Dispute Resolution</p></a></div></nav></div><aside class=sidebar></aside></div><footer class=footer><div class="container footer__container flex"><div class=footer__copyright>&copy; 2025 Ex Machina.
<span class=footer__copyright-credits>Generated with <a href=https://gohugo.io/ rel="nofollow noopener" target=_blank>Hugo</a> and <a href=https://github.com/Vimux/Mainroad/ rel="nofollow noopener" target=_blank>Mainroad</a> theme.</span></div></div></footer></div><script async defer src=/js/menu.js></script></body></html>