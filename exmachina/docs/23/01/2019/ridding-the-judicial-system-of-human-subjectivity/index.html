<!doctype html><html class=no-js lang=en><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><title>Ridding the judicial system of human subjectivity - Ex Machina</title><script>(function(e,t){e[t]=e[t].replace("no-js","js")})(document.documentElement,"className")</script><meta name=description content><meta property="og:url" content="http://rahulmatthan.github.io/23/01/2019/ridding-the-judicial-system-of-human-subjectivity/"><meta property="og:site_name" content="Ex Machina"><meta property="og:title" content="Ridding the judicial system of human subjectivity"><meta property="og:description" content="Algorithmic sentencing, using machine learning to assess recidivism risk, has demonstrated consistent outcomes. But is not without flaws, sometimes reflecting human biases. Despite imperfections, I believe algorithms can introduce objectivity and be fine-tuned to reduce biases, making them more reliable than human judgment."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2019-01-23T00:00:00+00:00"><meta property="article:modified_time" content="2019-01-23T00:00:00+00:00"><meta property="article:tag" content="Artificial Intelligence"><meta property="article:tag" content="Business of Law"><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=dns-prefetch href=//fonts.googleapis.com><link rel=dns-prefetch href=//fonts.gstatic.com><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700"><link rel=stylesheet href=/css/style.css><link rel="shortcut icon" href=/favicon.ico></head><body class=body><div class="container container--outer"><header class=header><div class="container header__container"><div class="logo logo--mixed"><a class=logo__link href=/ title="Ex Machina" rel=home><div class="logo__item logo__imagebox"><img class=logo__img src=/images/exmachina.jpg></div><div class="logo__item logo__text"><div class=logo__title>Ex Machina</div><div class=logo__tagline>Law. Technology. Society.</div></div></a></div><nav class=menu><button class=menu__btn aria-haspopup=true aria-expanded=false tabindex=0>
<span class=menu__btn-title tabindex=-1>Menu</span></button><ul class=menu__list><li class=menu__item><a class=menu__link href=/index/><span class=menu__text>Index</span></a></li><li class=menu__item><a class=menu__link href=/topics/><span class=menu__text>Topics</span></a></li><li class=menu__item><a class=menu__link href=/books/><i class='fa fa-road'></i>
<span class=menu__text>Books</span></a></li><li class=menu__item><a class=menu__link href=/podcast/><i class='fa fa-road'></i>
<span class=menu__text>Podcast</span></a></li><li class=menu__item><a class=menu__link href=/about/><i class='fa fa-road'></i>
<span class=menu__text>About</span></a></li></ul></nav></div></header><div class="wrapper flex"><div class=primary><main class=main role=main><article class=post><header class=post__header><h1 class=post__title>Ridding the judicial system of human subjectivity</h1><div class="post__meta meta"><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class=meta__text datetime=2019-01-23T00:00:00Z>January 23, 2019</time></div></div></header><div class="content post__content clearfix"><p><em>Algorithmic sentencing, using machine learning to assess recidivism risk, has demonstrated consistent outcomes. But is not without flaws, sometimes reflecting human biases. Despite imperfections, I believe algorithms can introduce objectivity and be fine-tuned to reduce biases, making them more reliable than human judgment.</em></p><p><em>This article was first published in The Mint. You can read the original at <a href=https://www.livemint.com/opinion/columns/opinion-ridding-the-judicial-system-of-human-subjectivity-1548174784792.html>this link</a>.</em></p><hr><p>If it is to be completely fair, a legal system must be consistent. For justice to be meted out, a decision handed down by one judge should not be very different from that pronounced by another in a case with largely similar facts. In reality, however, this is rarely the case.</p><p>To ascertain whether there is such a thing as judicial consistency, 47 district court judges from the state of Virginia, US, were asked to participate in a survey. Each judge was given five different hypothetical cases and asked to adjudicate on them. Far from displaying consistency, their decisions could not have been more widely divergent. In one case, of those who voted guilty, 44% recommended probation, 22% imposed a fine, 17% imposed probation and a fine while the rest suggested jail time. If a group of sitting judges, adjudicating on the same set of facts could come up with such widely disparate results, how can we hope for any measure of consistency when they rule on real cases?</p><p>With this in mind, a number of countries have put in place prescriptive systems designed to take human subjectivity out of sentencing. These systems are designed to ensure that individuals convicted of the same crime always receive the same sentence. However, by removing judicial discretion, they sometimes fail to appropriately consider important mitigating circumstances that help establish whether or not the person convicted of the offence has any chance of being rehabilitated. It, therefore, becomes important to find a way to empirically establish what the likelihood is that a convicted criminal will commit a crime again.</p><p>In 1928, Ernest Burgess came up with the concept of unit-weighted regression and applied it to the evaluation of recidivism risk in prison populations. He identified 21 measures and assigned to each of the convicts in his sample set a score of either zero or one against each parameter. When the scores were added up, he predicted that convicts with scores of between 14 and 21 had a high chance of parole success, while those with scores of four or less were likely to have a high rate of recidivism. When he tested his prediction against what actually happened, 98% of his low-risk group made it through parole without incident while 76% of his high-risk group did not.</p><p>By 1935, the Burgess method was being used in prisons in Illinois and variants of this mathematical approach began to be used around the world. As computers got more advanced, the algorithms designed to assess recidivism risk were able to take into consideration a significantly larger number of factors. With advances in machine learning, they could spot patterns that humans could not hope to see. Not only was this approach producing consistent results every time the same set of facts were presented, given the vast volumes of data these systems could process, their ability to accurately establish recidivism risk was far better than any human could hope to deliver.</p><p>That said, algorithmic sentencing is not perfect. When 19-year-old Christopher Brooks was convicted of statutory rape for having consensual sex with a minor, the judge relied on an algorithm for sentencing. This particular algorithm used the age gap between the victim and the accused to evaluate riskâ€”the greater the age gap, the lower the risk. This meant that, had Christopher been 36 years old, the age gap would have been so large that algorithm would have recommended that he serve no jail time. It is outcomes like this that have resulted in a public backlash against the use of algorithms in situations where such use could affect life and personal liberties.</p><p>The fact of the matter is that algorithms build their models on historical data sets, precedents that are themselves the outcome of decades of choices made by humans who are far from objective. We created objective algorithms because we knew that humans were inherently irrational in the decisions that they made. However, the solution we created seems to be infected with the same biases that we were aiming to eradicate.</p><p>Where does this leave us? Do we scrap algorithmic decision-making entirely and go back to relying on our uniquely human sense of justice? Most people will say they are more comfortable having their futures decided by a flesh and blood human being than by an inscrutable, soulless algorithm.</p><p>However, I am reluctant to go down that path. I find it impossible to ignore the evidence of decades of flawed human decision-making that characterises our judicial system. Our biases run so close to the surface that based on what we now know, it is clear that human decision can never be completely rational. Recent studies have shown that judges with daughters are more likely to issue decisions favourable to women while judges coming back from a recess are more likely to grant bail and those heading into one are unlikely to do so. The entire science of behavioural economics proves that as much as we might think we are behaving rationally, more often than not, we are just responding to unconscious biases.</p><p>Algorithms, while not perfect, can at least help introduce objectivity and eliminate random errors. Any flaws we discover in their outcomes can be fine-tuned to eliminate all the human biases that might have crept in. As long as we are mindful of their limitations, algorithms are likely to be more objective than either you or me.</p></div><footer class=post__footer><div class="post__tags tags clearfix"><svg class="tags__badge icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M32 19c0 1-1 2-1 2L21 31s-1 1-2 1-2-1-2-1L2 16c-1-1-1.4-2-1.4-2S0 12.5.0 11V3C0 1.5.8.8.8.8S1.5.0 3 0h8c1.5.0 3 .6 3 .6S15 1 16 2l15 15s1 1 1 2zM7 10a3 3 0 100-6 3 3 0 000 6z"/></svg><ul class=tags__list><li class=tags__item><a class="tags__link btn" href=/tags/artificial-intelligence/ rel=tag>Artificial Intelligence</a></li><li class=tags__item><a class="tags__link btn" href=/tags/business-of-law/ rel=tag>Business of Law</a></li></ul></div></footer></article></main><div class="authorbox clearfix"><figure class=authorbox__avatar><img alt="Rahul Matthan avatar" src=/images/avatar.png class=avatar height=90 width=90></figure><div class=authorbox__header><span class=authorbox__name>About Rahul Matthan</span></div><div class=authorbox__description>Rahul Matthan is a lawyer who works at the intersection of law, technology and society.</div></div><nav class="pager flex"><div class="pager__item pager__item--prev"><a class=pager__link href=/16/01/2019/time-to-redo-fdi-in-e-commerce-in-india/ rel=prev><span class=pager__subtitle>Â«&#8201;Previous</span><p class=pager__title>Time to redo FDI in e-commerce in India</p></a></div><div class="pager__item pager__item--next"><a class=pager__link href=/30/01/2019/account-aggregators-and-e-consent-for-credit-markets/ rel=next><span class=pager__subtitle>Next&#8201;Â»</span><p class=pager__title>Account aggregators and e-consent for credit markets</p></a></div></nav></div><aside class=sidebar></aside></div><footer class=footer><div class="container footer__container flex"><div class=footer__copyright>&copy; 2025 Ex Machina.
<span class=footer__copyright-credits>Generated with <a href=https://gohugo.io/ rel="nofollow noopener" target=_blank>Hugo</a> and <a href=https://github.com/Vimux/Mainroad/ rel="nofollow noopener" target=_blank>Mainroad</a> theme.</span></div></div></footer></div><script async defer src=/js/menu.js></script></body></html>