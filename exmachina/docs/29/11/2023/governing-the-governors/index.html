<!doctype html><html class=no-js lang=en><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><title>Governing the Governors - Ex Machina</title><script>(function(e,t){e[t]=e[t].replace("no-js","js")})(document.documentElement,"className")</script><meta name=description content><meta property="og:url" content="http://rahulmatthan.github.io/29/11/2023/governing-the-governors/"><meta property="og:site_name" content="Ex Machina"><meta property="og:title" content="Governing the Governors"><meta property="og:description" content="The events surrounding OpenAI and its CEO Sam Altman highlight the challenges in establishing effective governance structures that can appropriately control AI development. Given the profit motivation of private enterprise and the other narrow commercial interests that they are constrained by, we need to develop alternate robust frameworks that can operate beyond the influence of private commercial entities."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-11-29T00:00:00+00:00"><meta property="article:modified_time" content="2023-11-29T00:00:00+00:00"><meta property="article:tag" content="Artificial Intelligence"><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=dns-prefetch href=//fonts.googleapis.com><link rel=dns-prefetch href=//fonts.gstatic.com><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700"><link rel=stylesheet href=/css/style.css><link rel="shortcut icon" href=/favicon.ico></head><body class=body><div class="container container--outer"><header class=header><div class="container header__container"><div class="logo logo--mixed"><a class=logo__link href=/ title="Ex Machina" rel=home><div class="logo__item logo__imagebox"><img class=logo__img src=/images/exmachina.jpg></div><div class="logo__item logo__text"><div class=logo__title>Ex Machina</div><div class=logo__tagline>Law. Technology. Society.</div></div></a></div><nav class=menu><button class=menu__btn aria-haspopup=true aria-expanded=false tabindex=0>
<span class=menu__btn-title tabindex=-1>Menu</span></button><ul class=menu__list><li class=menu__item><a class=menu__link href=/index/><span class=menu__text>Index</span></a></li><li class=menu__item><a class=menu__link href=/topics/><span class=menu__text>Topics</span></a></li><li class=menu__item><a class=menu__link href=/books/><i class='fa fa-road'></i>
<span class=menu__text>Books</span></a></li><li class=menu__item><a class=menu__link href=/podcast/><i class='fa fa-road'></i>
<span class=menu__text>Podcast</span></a></li><li class=menu__item><a class=menu__link href=/about/><i class='fa fa-road'></i>
<span class=menu__text>About</span></a></li></ul></nav></div></header><div class="wrapper flex"><div class=primary><main class=main role=main><article class=post><header class=post__header><h1 class=post__title>Governing the Governors</h1><div class="post__meta meta"><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class=meta__text datetime=2023-11-29T00:00:00Z>November 29, 2023</time></div></div></header><div class="content post__content clearfix"><figure><img src=/images/governing-the-governors.jpg width=auto></figure><p><em>The events surrounding OpenAI and its CEO Sam Altman highlight the challenges in establishing effective governance structures that can appropriately control AI development. Given the profit motivation of private enterprise and the other narrow commercial interests that they are constrained by, we need to develop alternate robust frameworks that can operate beyond the influence of private commercial entities.</em></p><p><em>This article was first published in The Mint. You can read the original at <a href=https://www.livemint.com/opinion/online-views/the-openai-saga-has-placed-technology-governance-back-in-the-spotlight-11701178278668.html>this link</a>.</em></p><hr><p>All anyone was talking about last week was OpenAI.</p><p>Over the course of five short days, its chief executive officer Sam Altman was fired by the board, hired by Microsoft and reinstated as the head of OpenAI. But, while the events of last week were reported from the perspective of the 700 odd employees who threatened to walk out if their CEO was not reinstated, the tech giant whose $13 billion commitment to a company over whose board it had little control was imprudent to say the least, and also of the 37-year-old CEO who remains the undisputed face of today’s Generative Artificial Intelligence (AI) revolution, despite the drama, the long-term effects of the week’s events will be most deeply felt by the governance community, whose attempt at controlling the most transformative technology in over a century has truly failed.</p><h3 id=raison-detre>Raison d&rsquo;etre</h3><p>OpenAI was born out of a fear that commercially funded AI research labs—like Google’s DeepMind—were hidden from public gaze, which meant that the technologies they were creating could be dangerous and no one would be any wiser. It was to ensure that AI development proceeds in a safe and responsible manner that OpenAI was set up as a non-profit organisation with the objective of making sure “… artificial intelligence benefits humanity regardless of profit." Its original founders—Sam Altman and Elon Musk—committed up to $1 billion of their own money to a not-for-profit entity that had been established for that purpose.</p><p>Despite the generous initial commitment, it soon became clear that building a large language model was far more expensive than they had originally imagined. OpenAI was going to need far more capital than a non-profit would ordinarily be able to access. To marry the twin objectives of raising private capital while prioritising safety, OpenAI gave itself a somewhat unusual corporate structure in 2019—with a for-profit unit housed within an entity that was supervised by a not-for-profit board.</p><p>The not-for-profit board was vested with extraordinary powers in order to ensure that AI development proceeded safely. It was allowed to pull the plug if it believed that the company was going down a path that was harmful to society—even if that came at the cost of investments its shareholders had made. It was obliged to let nothing—neither the commercial interests of investors nor the hubris of the person at the helm of affairs—come in the way of ensuring that the AI that was being built was safe. The moment it believed that a line was about to be crossed, it was empowered to take extreme measures to prevent that.</p><h3 id=what-went-down>What Went Down</h3><p>This was the board that fired Sam Altman. It is still not clear, at the time of writing, what the exact reasons for his termination were. All that the board’s official statement said was that Altman had not been “consistently candid in his communications with the board."</p><p>What exactly was communicated or why the board believed he was not candid is still anyone’s guess—the board was under no obligation to provide reasons. Its singular mandate was to assure themselves that the path along which the company was currently proceeding continued to be of benefit to humanity. If directors believed for any reason that this was not the case, and that removing Sam Altman as CEO was necessary to set things back on track, they were well within their rights to show him the door.</p><p>This, as we all know, was not how things ended. In the face of vociferous protests from employees, pressure from its largest investor and a clamorous response from just about everyone in the tech community, Altman was reinstated as CEO five days after he was sacked. The board was also reconstituted with a group of individuals who, presumably, were less likely to depose him in the future. And with these changes, everyone seemed to relax, relieved that things had returned to what they should have been.</p><h3 id=responsible-data-governance>Responsible Data Governance</h3><p>But surely, even those who are happy with the outcome must realize that the safety net we thought we had put in place to protect us from malevolent AI lies well and truly breached. Let us, for a moment, assume that Altman was working on technologies that were a threat to humanity, and, knowing that the board would shut these down, had been less than candid with the information he had provided them. If this was indeed the case, the board was right to sack him. But what was the point of such a decision if all it would take to reverse it was a weekend’s worth of protests? Is this really our protection against a Skynet future?</p><p>Whenever the responsibility of establishing governance frameworks for matters of societal importance is left to private enterprise, the systems set up by the latter inevitably fall short. Corporate entities, even those that are governed by not-for-profit boards, are driven by narrow commercial incentives. They are incapable of finding a balance between their financial imperatives and the larger societal interest.</p><p>As I have often said in this column and in my other writing, we need a different approach to technology governance—one that is capable of withstanding the pressures that OpenAI’s board clearly was not. This will require us to free AI from the control of a single organisation that seems to be consolidating its grip over it.</p><p>Maybe it is also time to check if key elements of the techno-legal approach to data governance that we have perfected in relation to digital public infrastructure can be usefully applied to AI governance.</p></div><footer class=post__footer><div class="post__tags tags clearfix"><svg class="tags__badge icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M32 19c0 1-1 2-1 2L21 31s-1 1-2 1-2-1-2-1L2 16c-1-1-1.4-2-1.4-2S0 12.5.0 11V3C0 1.5.8.8.8.8S1.5.0 3 0h8c1.5.0 3 .6 3 .6S15 1 16 2l15 15s1 1 1 2zM7 10a3 3 0 100-6 3 3 0 000 6z"/></svg><ul class=tags__list><li class=tags__item><a class="tags__link btn" href=/tags/artificial-intelligence/ rel=tag>Artificial Intelligence</a></li></ul></div></footer></article></main><div class="authorbox clearfix"><figure class=authorbox__avatar><img alt="Rahul Matthan avatar" src=/images/avatar.png class=avatar height=90 width=90></figure><div class=authorbox__header><span class=authorbox__name>About Rahul Matthan</span></div><div class=authorbox__description>Rahul Matthan is a lawyer who works at the intersection of law, technology and society.</div></div><nav class="pager flex"><div class="pager__item pager__item--prev"><a class=pager__link href=/22/11/2023/no-one-left-behind/ rel=prev><span class=pager__subtitle>«&#8201;Previous</span><p class=pager__title>No-one Left Behind</p></a></div><div class="pager__item pager__item--next"><a class=pager__link href=/06/12/2023/human-writing/ rel=next><span class=pager__subtitle>Next&#8201;»</span><p class=pager__title>Human Writing</p></a></div></nav></div><aside class=sidebar></aside></div><footer class=footer><div class="container footer__container flex"><div class=footer__copyright>&copy; 2025 Ex Machina.
<span class=footer__copyright-credits>Generated with <a href=https://gohugo.io/ rel="nofollow noopener" target=_blank>Hugo</a> and <a href=https://github.com/Vimux/Mainroad/ rel="nofollow noopener" target=_blank>Mainroad</a> theme.</span></div></div></footer></div><script async defer src=/js/menu.js></script></body></html>