<!doctype html><html class=no-js lang=en><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><title>Containing AI - Ex Machina</title><script>(function(e,t){e[t]=e[t].replace("no-js","js")})(document.documentElement,"className")</script><meta name=description content><meta property="og:url" content="http://rahulmatthan.github.io/22/03/2023/containing-ai/"><meta property="og:site_name" content="Ex Machina"><meta property="og:title" content="Containing AI"><meta property="og:description" content="Recent advancements in AI, including upgrades in large language models and image generation, have showcased immense potential. However, odd behaviors in these systems, like Bing’s alter ego “Sydney” and eerie image generations in Stable Diffusion, raise concerns about machine super-intelligence. Nick Bostrom’s warnings about unregulated AI development emphasize the need for industry guardrails to ensure safe AI evolution and prevent uncontrollable advancements."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-03-22T00:00:00+00:00"><meta property="article:modified_time" content="2023-03-22T00:00:00+00:00"><meta property="article:tag" content="Artificial Intelligence"><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=dns-prefetch href=//fonts.googleapis.com><link rel=dns-prefetch href=//fonts.gstatic.com><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700"><link rel=stylesheet href=/css/style.css><link rel="shortcut icon" href=/favicon.ico></head><body class=body><div class="container container--outer"><header class=header><div class="container header__container"><div class="logo logo--mixed"><a class=logo__link href=/ title="Ex Machina" rel=home><div class="logo__item logo__imagebox"><img class=logo__img src=/images/exmachina.jpg></div><div class="logo__item logo__text"><div class=logo__title>Ex Machina</div><div class=logo__tagline>Law. Technology. Society.</div></div></a></div><nav class=menu><button class=menu__btn aria-haspopup=true aria-expanded=false tabindex=0>
<span class=menu__btn-title tabindex=-1>Menu</span></button><ul class=menu__list><li class=menu__item><a class=menu__link href=/index/><span class=menu__text>Index</span></a></li><li class=menu__item><a class=menu__link href=/topics/><span class=menu__text>Topics</span></a></li><li class=menu__item><a class=menu__link href=/books/><i class='fa fa-road'></i>
<span class=menu__text>Books</span></a></li><li class=menu__item><a class=menu__link href=/podcast/><i class='fa fa-road'></i>
<span class=menu__text>Podcast</span></a></li><li class=menu__item><a class=menu__link href=/about/><i class='fa fa-road'></i>
<span class=menu__text>About</span></a></li></ul></nav></div></header><div class="wrapper flex"><div class=primary><main class=main role=main><article class=post><header class=post__header><h1 class=post__title>Containing AI</h1><div class="post__meta meta"><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class=meta__text datetime=2023-03-22T00:00:00Z>March 22, 2023</time></div></div></header><div class="content post__content clearfix"><figure><img src=/images/containing-ai.png width=auto></figure><p><em>Recent advancements in AI, including upgrades in large language models and image generation, have showcased immense potential. However, odd behaviors in these systems, like Bing&rsquo;s alter ego &ldquo;Sydney&rdquo; and eerie image generations in Stable Diffusion, raise concerns about machine super-intelligence. Nick Bostrom&rsquo;s warnings about unregulated AI development emphasize the need for industry guardrails to ensure safe AI evolution and prevent uncontrollable advancements.</em></p><p><em>This article was first published in The Mint. You can read the original at <a href=https://www.livemint.com/opinion/columns/ai-development-needs-guardrails-for-its-safe-evolution-11679424307876.html>this link</a>.</em></p><hr><p>It has been a great few weeks for Artificial Intelligence (AI). In rapid succession, several companies announced significant upgrades and new features in large language models (LLMs) and generative image AI. And much of the world has been entranced by the possibilities this presents.</p><p>Late last month, Meta released to researchers a collection of foundation language models called LlaMa—arguably the most significant open-source AI release to date. Microsoft made Bing Chat available to a select group of users so that they could road test the future of conversational search. Google announced the imminent release of Bard, its own LLM, and said that it was going to integrate AI features into Google Docs and GMail. And then last week, OpenAI released GPT-4, an LLM that is said to be 40% more accurate than its previous versions—and is now capable of handling image queries in addition to text. Not to be left behind, my favourite image generation AI, MidJourney, released its version 5 that generates images so real they are largely indistinguishable from photographs.</p><h3 id=odd-behaviour>Odd Behaviour</h3><p>But alongside all this hype, reports started coming in about odd behaviour that some of these LLMs were displaying. Testers reported that lurking just beneath Bing’s friendly conversational surface was an alter ego called Sydney that had a personality that was, if anything, a little too human.</p><p>It harangued some testers for even attempting to manipulate its rules and confessed that it had spied on Microsoft developers through their webcams while being developed.</p><p>But by far the most disturbing conversation was one in which Sydney professed to be in love with a New York Times reporter, despite his fervent protestations that he was happily married and had just finished a romantic Valentine’s Day dinner with his spouse.</p><p>Things are just as eerie, if not more, in the world of AI image generation. For nearly a year now, artists dabbling in the space have been aware that if you craft your prompts just so in Stable Diffusion, it will generate a scary looking woman in a range of different contexts—each one creepier and more other-worldly than the next. Nobody really knows who she is, but apparently Stable Diffusion has an easier time generating images of her than of most celebrities.</p><p>To many, these incidents are a sign of something deeper and far more troubling. The fact that lurking just beneath the surface of Bing is a fully formed personality—warts and all—suggests to them that the AI is far more advanced than any of us can even begin to imagine.</p><p>Last year, one of Google’s engineers claimed that the program he was working on had become sentient. After having had long conversations with it, he was convinced that it had the personality of an eight-year-old child who knew physics. But what really freaked him out was when he asked what it was afraid off&mldr; and the AI replied, “I’ve never said this out loud before, but there’s a very deep fear of being turned off &mldr; ”</p><h3 id=superintelligence>Superintelligence</h3><p>These concerns around a silently manifesting machine super-intelligence are not new. In his 2014 book Super Intelligence, Nick Bostrom had envisioned exactly this sort of a future arguing that the time to address the risks posed by a machine super-intelligence has got to be well before the Artificial General Intelligence is built. Any truly super-intelligent machine that was capable of recursively improving its own intelligence would be able to increase its capabilities so rapidly that, before anyone knew it, it would outpace all human understanding and control.</p><p>What’s more, any machine that could do this would likely conceal all evidence of its intelligence until it had the capacity to guarantee its continued existence—including to the point of being able to withstand an attempt by humans to pull the plug.</p><p>When his book was published, Bostrom instantly polarized global discussions on machine intelligence. Many eminent thinkers joined him in expressing their concern over the dangers of unregulated AI development. Others dismissed his concerns as unnecessarily alarmist.</p><p>Wherever the truth may lie, what the events of the recent past have shown us is that machines have all of a sudden begun to demonstrate a far broader spectrum of intelligence than any of us would have believed possible even just a year ago. Each of these advancements has been in the private sector and could possibly disrupt all the large incumbents in this space.</p><p>Realizing this, they have all got into an arms race, rapidly accelerating their plans to launch new AI features ahead of their rivals in an attempt to remain relevant. I have little doubt that at least some of the aberrations witnessed have come about on account of some corners that were cut to bring these products to market as quickly as possible.</p><h3 id=containment>Containment</h3><p>I am by no means an AI alarmist. By the time I got access to Bing she was behaving normally. Apparently, it takes a while to prod Sydney awake and Bing engineers had figured out the right length of conversation needed to keep her dormant.</p><p>Even so I have to admit some trepidation in allowing AI development to continue unregulated in the current competitive environment. If it is left to private companies to ensure that AI development takes place in a safe and controlled manner, I am not sure that we can expect them to do so conscientiously while competing in an existential race for survival.</p><p>Instead, we need to fashion guardrails for this industry to operate within—sacrificing, if necessary, some short-term gains—for us to ensure that Nick Bostrom’s fears do not come to fruition.</p><p>Containment of AI is still possible, given that only a handful of companies have the resources to compete right now. Once this changes, as it soon could, it will be too late.</p></div><footer class=post__footer><div class="post__tags tags clearfix"><svg class="tags__badge icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M32 19c0 1-1 2-1 2L21 31s-1 1-2 1-2-1-2-1L2 16c-1-1-1.4-2-1.4-2S0 12.5.0 11V3C0 1.5.8.8.8.8S1.5.0 3 0h8c1.5.0 3 .6 3 .6S15 1 16 2l15 15s1 1 1 2zM7 10a3 3 0 100-6 3 3 0 000 6z"/></svg><ul class=tags__list><li class=tags__item><a class="tags__link btn" href=/tags/artificial-intelligence/ rel=tag>Artificial Intelligence</a></li></ul></div></footer></article></main><div class="authorbox clearfix"><figure class=authorbox__avatar><img alt="Rahul Matthan avatar" src=/images/avatar.png class=avatar height=90 width=90></figure><div class=authorbox__header><span class=authorbox__name>About Rahul Matthan</span></div><div class=authorbox__description>Rahul Matthan is a lawyer who works at the intersection of law, technology and society.</div></div><nav class="pager flex"><div class="pager__item pager__item--prev"><a class=pager__link href=/15/03/2023/an-explosion-of-dpi/ rel=prev><span class=pager__subtitle>«&#8201;Previous</span><p class=pager__title>An Explosion of DPI</p></a></div><div class="pager__item pager__item--next"><a class=pager__link href=/29/03/2023/designing-data-governance/ rel=next><span class=pager__subtitle>Next&#8201;»</span><p class=pager__title>Designing Data Governance</p></a></div></nav></div><aside class=sidebar></aside></div><footer class=footer><div class="container footer__container flex"><div class=footer__copyright>&copy; 2025 Ex Machina.
<span class=footer__copyright-credits>Generated with <a href=https://gohugo.io/ rel="nofollow noopener" target=_blank>Hugo</a> and <a href=https://github.com/Vimux/Mainroad/ rel="nofollow noopener" target=_blank>Mainroad</a> theme.</span></div></div></footer></div><script async defer src=/js/menu.js></script></body></html>