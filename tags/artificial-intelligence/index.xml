<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Artificial Intelligence on Ex Machina</title>
    <link>http://rahulmatthan.github.io/tags/artificial-intelligence/</link>
    <description>Recent content in Artificial Intelligence on Ex Machina</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Wed, 11 Dec 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://rahulmatthan.github.io/tags/artificial-intelligence/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>A New AI Law</title>
      <link>http://rahulmatthan.github.io/11/12/2024/a-new-ai-law/</link>
      <pubDate>Wed, 11 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://rahulmatthan.github.io/11/12/2024/a-new-ai-law/</guid>
      <description>&lt;figure&gt;&lt;img src=&#34;http://rahulmatthan.github.io/images/a-new-ai-law.jpg&#34; width=&#34;auto&#34;&gt;&#xA;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;There are many who claim that the harms AI can cause can only be addressed by a new legislation specifically designed to address them. That said existing laws have, more often than not, been framed in terms that are broad enough to deal with these harms regardless of the technology that caused them.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI Liability</title>
      <link>http://rahulmatthan.github.io/27/11/2024/ai-liability/</link>
      <pubDate>Wed, 27 Nov 2024 00:00:00 +0000</pubDate>
      <guid>http://rahulmatthan.github.io/27/11/2024/ai-liability/</guid>
      <description>&lt;figure&gt;&lt;img src=&#34;http://rahulmatthan.github.io/images/ai-liability.jpg&#34; width=&#34;auto&#34;&gt;&#xA;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;AI is a probalistic, non-deterministic technology. This is the reason why it is capable of doing much of what we appreciate it for. However, this does not align with our legal system that is binary in application. We need to rethink our approach to liability if we are to avail the benefits of AI.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI Optimisation</title>
      <link>http://rahulmatthan.github.io/30/10/2024/ai-optimisation/</link>
      <pubDate>Wed, 30 Oct 2024 00:00:00 +0000</pubDate>
      <guid>http://rahulmatthan.github.io/30/10/2024/ai-optimisation/</guid>
      <description>&lt;figure&gt;&lt;img src=&#34;http://rahulmatthan.github.io/images/ai-optimisation.jpg&#34; width=&#34;auto&#34;&gt;&#xA;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;As we rely more and more on AI for information it is almost inevitable that companies will try to game the answer these AI chatbots provide to ensure that information favourable to them bubbles to the top. This has already begun to happen and it is only a matter of time before AI optimisation replaces SEO.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Learning to Read</title>
      <link>http://rahulmatthan.github.io/25/09/2024/learning-to-read/</link>
      <pubDate>Wed, 25 Sep 2024 00:00:00 +0000</pubDate>
      <guid>http://rahulmatthan.github.io/25/09/2024/learning-to-read/</guid>
      <description>&lt;figure&gt;&lt;img src=&#34;http://rahulmatthan.github.io/images/learning-to-read.jpg&#34; width=&#34;auto&#34;&gt;&#xA;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;AI really comes into its own when we need customised solutions at scale. If we can identify use cases in which human intervention is simply not practical given the complexity and diversity of outcomes, AI might just be able to offer a way out. Such as, for instance, to provide bespoke education outcomes.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Storytelling Reimagined</title>
      <link>http://rahulmatthan.github.io/07/08/2024/storytelling-reimagined/</link>
      <pubDate>Wed, 07 Aug 2024 00:00:00 +0000</pubDate>
      <guid>http://rahulmatthan.github.io/07/08/2024/storytelling-reimagined/</guid>
      <description>&lt;figure&gt;&lt;img src=&#34;http://rahulmatthan.github.io/images/storytelling-reimagined.jpg&#34; width=&#34;auto&#34;&gt;&#xA;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;There is no doubt that AI will fundamentally change the ways in which films are made. But rather than worry about how this might affect the film-making process, we should embrace the change that is about to come and use it to think up new approaches to story-telling.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Open AI Innovation</title>
      <link>http://rahulmatthan.github.io/31/07/2024/open-ai-innovation/</link>
      <pubDate>Wed, 31 Jul 2024 00:00:00 +0000</pubDate>
      <guid>http://rahulmatthan.github.io/31/07/2024/open-ai-innovation/</guid>
      <description>&lt;figure&gt;&lt;img src=&#34;http://rahulmatthan.github.io/images/open-ai-innovation.jpg&#34; width=&#34;auto&#34;&gt;&#xA;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;All innovations build on those that came before. It is important to strike a balance between leveraging intellectual property protection for commercial benefit and stifling innovation in the process. And this is particularly relevant in the context of AI.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Time Limited Arguments</title>
      <link>http://rahulmatthan.github.io/03/07/2024/time-limited-arguments/</link>
      <pubDate>Wed, 03 Jul 2024 00:00:00 +0000</pubDate>
      <guid>http://rahulmatthan.github.io/03/07/2024/time-limited-arguments/</guid>
      <description>&lt;figure&gt;&lt;img src=&#34;http://rahulmatthan.github.io/images/time-limited-arguments.jpg&#34; width=&#34;auto&#34;&gt;&#xA;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Everyone agrees that there is an urgent need to reform many aspects of the judicial system. One way to do this might be to re-consider the reliance we currently place on oral advocacy and try and find an alternative way of doing things. Maybe even get rid of it entirely.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI Companions</title>
      <link>http://rahulmatthan.github.io/19/06/2024/ai-companions/</link>
      <pubDate>Wed, 19 Jun 2024 00:00:00 +0000</pubDate>
      <guid>http://rahulmatthan.github.io/19/06/2024/ai-companions/</guid>
      <description>&lt;figure&gt;&lt;img src=&#34;http://rahulmatthan.github.io/images/ai-companion.jpg&#34; width=&#34;auto&#34;&gt;&#xA;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;One of the fastest growing categories of AI services is artificial companions. Recent advances in large language models have significantly accelerated its proliferation. But as much as there are benefits to conversational engagement with artificial intelligence, there are psychological implications we will have to consider.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Good Governance</title>
      <link>http://rahulmatthan.github.io/12/06/2024/good-governance/</link>
      <pubDate>Wed, 12 Jun 2024 00:00:00 +0000</pubDate>
      <guid>http://rahulmatthan.github.io/12/06/2024/good-governance/</guid>
      <description>&lt;figure&gt;&lt;img src=&#34;http://rahulmatthan.github.io/images/good-governance.jpg&#34; width=&#34;auto&#34;&gt;&#xA;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Good governance often calls for placing the values of the organisation ahead of short term gains. This is particularly important in AI, where the demands of investor to make quick returns can very easily incentivise companies to play fast and loose with safety.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Diversity Through AI</title>
      <link>http://rahulmatthan.github.io/05/06/2024/diversity-through-ai/</link>
      <pubDate>Wed, 05 Jun 2024 00:00:00 +0000</pubDate>
      <guid>http://rahulmatthan.github.io/05/06/2024/diversity-through-ai/</guid>
      <description>&lt;figure&gt;&lt;img src=&#34;http://rahulmatthan.github.io/images/ai-diversity.jpg&#34; width=&#34;auto&#34;&gt;&#xA;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Artificial Intelligence has the potential to significantly enhance our digital public infrastructure by bringing variety to a DPI approach that has so far been optimised for standardisation.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Controlling AI Export</title>
      <link>http://rahulmatthan.github.io/22/05/2024/controlling-ai-export/</link>
      <pubDate>Wed, 22 May 2024 00:00:00 +0000</pubDate>
      <guid>http://rahulmatthan.github.io/22/05/2024/controlling-ai-export/</guid>
      <description>&lt;figure&gt;&lt;img src=&#34;http://rahulmatthan.github.io/images/controlling-ai-export.jpg&#34; width=&#34;auto&#34;&gt;&#xA;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;There has been growing concerns around the risks of open source AI. In the recent past these have begun to manifest themselves in the form of export restrictions on open source AI models - that could have a deleterious effect on India&amp;rsquo;s AI strategy.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Getting AI to Work for You</title>
      <link>http://rahulmatthan.github.io/17/04/2024/getting-ai-to-work-for-you/</link>
      <pubDate>Wed, 17 Apr 2024 00:00:00 +0000</pubDate>
      <guid>http://rahulmatthan.github.io/17/04/2024/getting-ai-to-work-for-you/</guid>
      <description>&lt;figure&gt;&lt;img src=&#34;http://rahulmatthan.github.io/images/getting-ai-to-work-for-you.jpg&#34; width=&#34;auto&#34;&gt;&#xA;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Artificial intelligence might eventually replace us. But it still has a long way to go. In the meantime, rather than fretting about what might be, we should learn to use it so that we can make the most of all the efficiencies it offers. Here is how I do that.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Technophobia</title>
      <link>http://rahulmatthan.github.io/13/03/2024/technophobia/</link>
      <pubDate>Wed, 13 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://rahulmatthan.github.io/13/03/2024/technophobia/</guid>
      <description>&lt;figure&gt;&lt;img src=&#34;http://rahulmatthan.github.io/images/technophobia.jpg&#34; width=&#34;auto&#34;&gt;&#xA;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;We tend to resist change. We worry about the ways in which it could alter our existing way of life and the harms that could result as a consequence. But these technological changes almost always end up being nowhere near as frightening as they first seemed.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Learning from Failure</title>
      <link>http://rahulmatthan.github.io/29/02/2024/learning-from-failure/</link>
      <pubDate>Thu, 29 Feb 2024 00:00:00 +0000</pubDate>
      <guid>http://rahulmatthan.github.io/29/02/2024/learning-from-failure/</guid>
      <description>&lt;figure&gt;&lt;img src=&#34;http://rahulmatthan.github.io/images/ser.jpg&#34; width=&#34;auto&#34;&gt;&#xA;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;We need to encourage a culture of failure around AI so that when it fails we can understand why and disseminate those learnings throughout the industry. It is only when we can fail without fear that we will learn to do what it takes to build safe AI systems.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>CAS Regulations for AI</title>
      <link>http://rahulmatthan.github.io/14/02/2024/cas-regulations-for-ai/</link>
      <pubDate>Wed, 14 Feb 2024 00:00:00 +0000</pubDate>
      <guid>http://rahulmatthan.github.io/14/02/2024/cas-regulations-for-ai/</guid>
      <description>&lt;figure&gt;&lt;img src=&#34;http://rahulmatthan.github.io/images/ey.jpg&#34; width=&#34;auto&#34;&gt;&#xA;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;The PM-EAC suggests that AI should be regulated as a complex adaptive system. While there is a lot to say about this approach, in its articulation, the paper fails to take into account many of the essential features of modern AI.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Liars Dividend</title>
      <link>http://rahulmatthan.github.io/31/01/2024/liars-dividend/</link>
      <pubDate>Wed, 31 Jan 2024 00:00:00 +0000</pubDate>
      <guid>http://rahulmatthan.github.io/31/01/2024/liars-dividend/</guid>
      <description>&lt;figure&gt;&lt;img src=&#34;http://rahulmatthan.github.io/images/sachin-tendulkar.jpg&#34; width=&#34;auto&#34;&gt;&#xA;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;There is widespread consternation around the impact that deep-fakes are going to have on all of society this year. But most legislative counter-measures are oriented towards shooting the messenger. We need a different path. Thankfully we have been here before.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>NYT v. the LLMs</title>
      <link>http://rahulmatthan.github.io/03/01/2024/nyt-v.-the-llms/</link>
      <pubDate>Wed, 03 Jan 2024 00:00:00 +0000</pubDate>
      <guid>http://rahulmatthan.github.io/03/01/2024/nyt-v.-the-llms/</guid>
      <description>&lt;figure&gt;&lt;img src=&#34;http://rahulmatthan.github.io/images/nyt-v-the-llms.jpg&#34; width=&#34;auto&#34;&gt;&#xA;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;In the last week of 2023, the New York Times sued OpenAI and Microsoft for copyright infringement. The allegations in the complaint go to the core of how generative AI works and could shape the manner in which AI works going forward.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Looking Back on 2023</title>
      <link>http://rahulmatthan.github.io/27/12/2023/looking-back-on-2023/</link>
      <pubDate>Wed, 27 Dec 2023 00:00:00 +0000</pubDate>
      <guid>http://rahulmatthan.github.io/27/12/2023/looking-back-on-2023/</guid>
      <description>&lt;figure&gt;&lt;img src=&#34;http://rahulmatthan.github.io/images/looking-back-on-2023.jpg&#34; width=&#34;auto&#34;&gt;&#xA;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;2023 was the year in which DPI assumed its rightful place on the world stage. It was also the year in which artificial intelligence came into its own. There has never been a more interesting time to be engaged in technology policy.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI for the Global South</title>
      <link>http://rahulmatthan.github.io/13/12/2023/ai-for-the-global-south/</link>
      <pubDate>Wed, 13 Dec 2023 00:00:00 +0000</pubDate>
      <guid>http://rahulmatthan.github.io/13/12/2023/ai-for-the-global-south/</guid>
      <description>&lt;figure&gt;&lt;img src=&#34;http://rahulmatthan.github.io/images/ai-for-the-global-south.jpg&#34; width=&#34;auto&#34;&gt;&#xA;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;The European Union has agreed to a new law to regulate artificial intelligence (AI) by imposing transparency requirements on general AI models and stronger restrictions on more powerful models. The US offers a broader, more nuanced framework. However there exists a North-South divide - with the Global South viewing AI as beneficial as contrasted to the more risk-focused approach of the Global North.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Human Writing</title>
      <link>http://rahulmatthan.github.io/06/12/2023/human-writing/</link>
      <pubDate>Wed, 06 Dec 2023 00:00:00 +0000</pubDate>
      <guid>http://rahulmatthan.github.io/06/12/2023/human-writing/</guid>
      <description>&lt;figure&gt;&lt;img src=&#34;http://rahulmatthan.github.io/images/human-writing.jpg&#34; width=&#34;auto&#34;&gt;&#xA;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;When man invented writing he enabled the creation of a hive-mind that eventually lead to the establishment of civilisation as we know it. The advent of large language models has exponentially expanded that hive-mind but has it done so at the cost of our humanity?&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Governing the Governors</title>
      <link>http://rahulmatthan.github.io/29/11/2023/governing-the-governors/</link>
      <pubDate>Wed, 29 Nov 2023 00:00:00 +0000</pubDate>
      <guid>http://rahulmatthan.github.io/29/11/2023/governing-the-governors/</guid>
      <description>&lt;figure&gt;&lt;img src=&#34;http://rahulmatthan.github.io/images/governing-the-governors.jpg&#34; width=&#34;auto&#34;&gt;&#xA;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;The events surrounding OpenAI and its CEO Sam Altman highlight the challenges in establishing effective governance structures that can appropriately control AI development. Given the profit motivation of private enterprise and the other narrow commercial interests that they are constrained by, we need to develop alternate robust frameworks that can operate beyond the influence of private commercial entities.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Pandora&#39;s Box</title>
      <link>http://rahulmatthan.github.io/01/11/2023/pandoras-box/</link>
      <pubDate>Wed, 01 Nov 2023 00:00:00 +0000</pubDate>
      <guid>http://rahulmatthan.github.io/01/11/2023/pandoras-box/</guid>
      <description>&lt;figure&gt;&lt;img src=&#34;http://rahulmatthan.github.io/images/pandoras-box.png&#34; width=&#34;auto&#34;&gt;&#xA;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;The myth of Pandora&amp;rsquo;s box, where opening a forbidden container unleashed the world&amp;rsquo;s evils but also hope, parallels scientific discovery. Each breakthrough, like CRISPR&amp;rsquo;s medical potential, brings unforeseen challenges, as seen with its controversial use in gene editing. Technologies intended for good, like the internet or drones, can be subverted for harm. Regulation alone can&amp;rsquo;t contain such knowledge; instead, we must design incentives to align technology use with societal goals, preparing us to handle the inevitable consequences of human curiosity.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Managing AI Disruption</title>
      <link>http://rahulmatthan.github.io/27/09/2023/managing-ai-disruption/</link>
      <pubDate>Wed, 27 Sep 2023 00:00:00 +0000</pubDate>
      <guid>http://rahulmatthan.github.io/27/09/2023/managing-ai-disruption/</guid>
      <description>&lt;figure&gt;&lt;img src=&#34;http://rahulmatthan.github.io/images/managing-ai-disruption.png&#34; width=&#34;auto&#34;&gt;&#xA;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Society&amp;rsquo;s response to disruptive technologies like AI follows a three-stage pattern: regulation, adaptation, and acceptance. Regulations tend to focus on first-order concerns, but overlook second-order consequences like the potential erosion of democratic values due to increased transparency of knowledge.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Proof of Humanness</title>
      <link>http://rahulmatthan.github.io/23/08/2023/proof-of-humanness/</link>
      <pubDate>Wed, 23 Aug 2023 00:00:00 +0000</pubDate>
      <guid>http://rahulmatthan.github.io/23/08/2023/proof-of-humanness/</guid>
      <description>&lt;figure&gt;&lt;img src=&#34;http://rahulmatthan.github.io/images/proof-of-humanness.png&#34; width=&#34;auto&#34;&gt;&#xA;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Worldcoin has been designed to address the concern that in a world saturated with artificial intelligence we are going to need a proof of humanness. As true as that might be, I believe we need to go much further. And also tackle truth in content.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Mad AI Disease</title>
      <link>http://rahulmatthan.github.io/26/07/2023/mad-ai-disease/</link>
      <pubDate>Wed, 26 Jul 2023 00:00:00 +0000</pubDate>
      <guid>http://rahulmatthan.github.io/26/07/2023/mad-ai-disease/</guid>
      <description>&lt;figure&gt;&lt;img src=&#34;http://rahulmatthan.github.io/images/mad-ai-disease.png&#34; width=&#34;auto&#34;&gt;&#xA;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Large language models require training data sets in order to continuously improve. However, given the rate at which models are growing we are soon going to run out of training data. And synthetic data is not the solution we thought it might be.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Neither Good Nor Bad</title>
      <link>http://rahulmatthan.github.io/05/07/2023/neither-good-nor-bad/</link>
      <pubDate>Wed, 05 Jul 2023 00:00:00 +0000</pubDate>
      <guid>http://rahulmatthan.github.io/05/07/2023/neither-good-nor-bad/</guid>
      <description>&lt;figure&gt;&lt;img src=&#34;http://rahulmatthan.github.io/images/neither-good-nor-bad.png&#34; width=&#34;auto&#34;&gt;&#xA;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;We tend to think of technology as either “good” nor “bad” based on the outcomes it has. This is futile as in most instances any harms that may be caused by technology is on account of how it is used and by whom.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Musical Intelligence</title>
      <link>http://rahulmatthan.github.io/21/06/2023/musical-intelligence/</link>
      <pubDate>Wed, 21 Jun 2023 00:00:00 +0000</pubDate>
      <guid>http://rahulmatthan.github.io/21/06/2023/musical-intelligence/</guid>
      <description>&lt;figure&gt;&lt;img src=&#34;http://rahulmatthan.github.io/images/musical-intelligence.png&#34; width=&#34;auto&#34;&gt;&#xA;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;As artificial intelligence enters into the music industry, incumbents have already begun to resist the transformation it will inevitably bring. But change is inevitable and it is only those artists who are able to embrace it who will survive the transition.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Fear of the Unknown</title>
      <link>http://rahulmatthan.github.io/14/06/2023/fear-of-the-unknown/</link>
      <pubDate>Wed, 14 Jun 2023 00:00:00 +0000</pubDate>
      <guid>http://rahulmatthan.github.io/14/06/2023/fear-of-the-unknown/</guid>
      <description>&lt;figure&gt;&lt;img src=&#34;http://rahulmatthan.github.io/images/fear-of-the-unknown.png&#34; width=&#34;auto&#34;&gt;&#xA;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Our instinctive reaction to new and revolutionary technology is often fear of consequences that we cannot predict. But if we can rein in our instincts and conquer our fears, maybe we can master of the technology.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Rule Makers</title>
      <link>http://rahulmatthan.github.io/31/05/2023/rule-makers/</link>
      <pubDate>Wed, 31 May 2023 00:00:00 +0000</pubDate>
      <guid>http://rahulmatthan.github.io/31/05/2023/rule-makers/</guid>
      <description>&lt;figure&gt;&lt;img src=&#34;http://rahulmatthan.github.io/images/rule-makers.png&#34; width=&#34;auto&#34;&gt;&#xA;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;We have, for most of our existence as a nation, accepted the governance frameworks that have already been implemented elsewhere in the world. With digital public infrastructure India is, perhaps for the first time, making the rules. It is time for us to stop being rule-takers and assume the role of rule-makers.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>In-Built Bias</title>
      <link>http://rahulmatthan.github.io/24/05/2023/in-built-bias/</link>
      <pubDate>Wed, 24 May 2023 00:00:00 +0000</pubDate>
      <guid>http://rahulmatthan.github.io/24/05/2023/in-built-bias/</guid>
      <description>&lt;figure&gt;&lt;img src=&#34;http://rahulmatthan.github.io/images/in-built-bias.png&#34; width=&#34;auto&#34;&gt;&#xA;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;When healthcare is powered by artificial intelligence and smart devices, we must ensure that all of humanity stands to benefit. We need open, transparent and customisable algorithms in our hardware.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Ill-Advised Advisory</title>
      <link>http://rahulmatthan.github.io/17/05/2023/ill-advised-advisory/</link>
      <pubDate>Wed, 17 May 2023 00:00:00 +0000</pubDate>
      <guid>http://rahulmatthan.github.io/17/05/2023/ill-advised-advisory/</guid>
      <description>&lt;figure&gt;&lt;img src=&#34;http://rahulmatthan.github.io/images/ill-advised-advisory.png&#34; width=&#34;auto&#34;&gt;&#xA;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Regulators believe that the moment a new technology comes around they need to flex their regulatory muscle to wrestle it under control. In most instances they would be far better off waiting till they fully understand all the dimensions of the problem before acting. The new CERT-In advisory on generative AI is a case in point.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI&#39;s GDPR Problem</title>
      <link>http://rahulmatthan.github.io/26/04/2023/ais-gdpr-problem/</link>
      <pubDate>Wed, 26 Apr 2023 00:00:00 +0000</pubDate>
      <guid>http://rahulmatthan.github.io/26/04/2023/ais-gdpr-problem/</guid>
      <description>&lt;figure&gt;&lt;img src=&#34;http://rahulmatthan.github.io/images/ai-has-a-gdpr-problem.jpg&#34; width=&#34;auto&#34;&gt;&#xA;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Recent discussions on AI regulation often focus on privacy concerns, especially in relation to the GDPR. Large Language Models (LLMs) can conflict with GDPR principles like consent, data minimization, and retention. Conversational AI&amp;rsquo;s potential to store personal data raises further concerns. However, instead of constraining AI within outdated laws, regulatory frameworks should evolve to accommodate and enable new technologies, balancing innovation with privacy.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Pro-Innovation Regulation</title>
      <link>http://rahulmatthan.github.io/12/04/2023/pro-innovation-regulation/</link>
      <pubDate>Wed, 12 Apr 2023 00:00:00 +0000</pubDate>
      <guid>http://rahulmatthan.github.io/12/04/2023/pro-innovation-regulation/</guid>
      <description>&lt;figure&gt;&lt;img src=&#34;http://rahulmatthan.github.io/images/pro-innovation-ai-regulation.png&#34; width=&#34;auto&#34;&gt;&#xA;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;While AI will transform society and make certain jobs obsolete, it will also create new opportunities. Different countries have proposed varied regulatory approaches, from the US&amp;rsquo;s hands-off stance to the EU&amp;rsquo;s detailed guidelines. The UK&amp;rsquo;s agile, principle-based approach, which adapts based on experience and avoids rigid legislation, is recommended for India to harness AI&amp;rsquo;s potential without stifling innovation.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Containing AI</title>
      <link>http://rahulmatthan.github.io/22/03/2023/containing-ai/</link>
      <pubDate>Wed, 22 Mar 2023 00:00:00 +0000</pubDate>
      <guid>http://rahulmatthan.github.io/22/03/2023/containing-ai/</guid>
      <description>&lt;figure&gt;&lt;img src=&#34;http://rahulmatthan.github.io/images/containing-ai.png&#34; width=&#34;auto&#34;&gt;&#xA;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Recent advancements in AI, including upgrades in large language models and image generation, have showcased immense potential. However, odd behaviors in these systems, like Bing&amp;rsquo;s alter ego &amp;ldquo;Sydney&amp;rdquo; and eerie image generations in Stable Diffusion, raise concerns about machine super-intelligence. Nick Bostrom&amp;rsquo;s warnings about unregulated AI development emphasize the need for industry guardrails to ensure safe AI evolution and prevent uncontrollable advancements.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Does AI Copy</title>
      <link>http://rahulmatthan.github.io/15/02/2023/does-ai-copy/</link>
      <pubDate>Wed, 15 Feb 2023 00:00:00 +0000</pubDate>
      <guid>http://rahulmatthan.github.io/15/02/2023/does-ai-copy/</guid>
      <description>&lt;figure&gt;&lt;img src=&#34;http://rahulmatthan.github.io/images/does-ai-copy.png&#34; width=&#34;auto&#34;&gt;&#xA;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Generative AI has had a transformative impact on text and visual arts. While the AI&amp;rsquo;s ability to mimic artistic styles raises copyright concerns, does this constitutes &amp;ldquo;copying&amp;rdquo;? How will the definition of artistic talent evolve in the AI era?&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Momentous Change</title>
      <link>http://rahulmatthan.github.io/04/01/2023/momentous-change/</link>
      <pubDate>Wed, 04 Jan 2023 00:00:00 +0000</pubDate>
      <guid>http://rahulmatthan.github.io/04/01/2023/momentous-change/</guid>
      <description>&lt;figure&gt;&lt;img src=&#34;http://rahulmatthan.github.io/images/momentous-change.jpg&#34; width=&#34;auto&#34;&gt;&#xA;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;The transformative potential of OpenAI&amp;rsquo;s ChatGPT is like how Google revolutionised search. ChatGPT could disrupt the targeted advertising model that sustains most internet businesses by providing summarized information instead of directing users to specific websites. The technology&amp;rsquo;s potential to change the internet&amp;rsquo;s fundamental business model is emphasized.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Truth and LLMs</title>
      <link>http://rahulmatthan.github.io/14/12/2022/truth-and-llms/</link>
      <pubDate>Wed, 14 Dec 2022 00:00:00 +0000</pubDate>
      <guid>http://rahulmatthan.github.io/14/12/2022/truth-and-llms/</guid>
      <description>&lt;figure&gt;&lt;img src=&#34;http://rahulmatthan.github.io/images/truth-and-llms.jpg&#34; width=&#34;auto&#34;&gt;&#xA;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Education is evolving in the age of technology and AI. While modern education is moving away from rote learning to skills like critical thinking, students should also be trained to use AI as a research tool. However, the rise of AI-generated content poses challenges in distinguishing genuine research from fabricated material, necessitating the teaching of healthy skepticism and cross-referencing skills to students.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>It&#39;s Getting Real</title>
      <link>http://rahulmatthan.github.io/18/10/2022/its-getting-real/</link>
      <pubDate>Tue, 18 Oct 2022 00:00:00 +0000</pubDate>
      <guid>http://rahulmatthan.github.io/18/10/2022/its-getting-real/</guid>
      <description>&lt;figure&gt;&lt;img src=&#34;http://rahulmatthan.github.io/images/its-getting-real.jpg&#34; width=&#34;auto&#34;&gt;&#xA;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;AI is being increasingly used in journalism and law. OpenAI&amp;rsquo;s GPT-3, can produce content nearly indistinguishable from human-written work. But we need to remember that AI is a tool, not a substitute for human creativity.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>The Language Barrier</title>
      <link>http://rahulmatthan.github.io/17/08/2022/the-language-barrier/</link>
      <pubDate>Wed, 17 Aug 2022 00:00:00 +0000</pubDate>
      <guid>http://rahulmatthan.github.io/17/08/2022/the-language-barrier/</guid>
      <description>&lt;figure&gt;&lt;img src=&#34;http://rahulmatthan.github.io/images/language-barrier.jpg&#34; width=&#34;auto&#34;&gt;&#xA;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;There are parallels between the myth of the Tower of Babel and the modern linguistic challenge of the internet. In this India has a unique need for translation technology, given its linguistic diversity. Bhashini may be the answer.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Should AI own IP</title>
      <link>http://rahulmatthan.github.io/27/10/2021/should-ai-own-ip/</link>
      <pubDate>Wed, 27 Oct 2021 00:00:00 +0000</pubDate>
      <guid>http://rahulmatthan.github.io/27/10/2021/should-ai-own-ip/</guid>
      <description>&lt;p&gt;&lt;em&gt;The South African patent office has granted a patent to an artificial intelligence program for an invention it has made. India granted a copyright to an AI application along similar lines. It is not clear how an artificial intelligence can exercise the IP granted by prosecuting a breach or negotiating commercial arrangements for its license. All these actions will have to be taken by humans on behalf of the AI in which case what is the point in calling the algorithm an inventor.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>We Don&#39;t Need Large Datasets</title>
      <link>http://rahulmatthan.github.io/02/09/2020/we-dont-need-large-datasets/</link>
      <pubDate>Wed, 02 Sep 2020 00:00:00 +0000</pubDate>
      <guid>http://rahulmatthan.github.io/02/09/2020/we-dont-need-large-datasets/</guid>
      <description>&lt;p&gt;&lt;em&gt;Ford&amp;rsquo;s internal combustion engine car beat Edison&amp;rsquo;s EV to the market and as a result we are on our current fossil fuel dependent path. What if things were different. Few Shot Learning is an alternative to data guzzling artificial intelligence models that allows us to not be dependent on large datasets.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>It’s better to use incentives than diktats to develop AI</title>
      <link>http://rahulmatthan.github.io/04/09/2019/its-better-to-use-incentives-than-diktats-to-develop-ai/</link>
      <pubDate>Wed, 04 Sep 2019 00:00:00 +0000</pubDate>
      <guid>http://rahulmatthan.github.io/04/09/2019/its-better-to-use-incentives-than-diktats-to-develop-ai/</guid>
      <description>&lt;p&gt;&lt;em&gt;The argument that data localization will boost India&amp;rsquo;s AI competence is flawed. Simply storing data in-country doesn&amp;rsquo;t translate to AI development, as data structures are company-specific and insights are often non-transferable. Instead, focusing on building AI infrastructure, incentivizing researchers, and encouraging homegrown AI development with existing data is more effective for fostering AI prowess.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Rising machine intelligence is a double-edged sword</title>
      <link>http://rahulmatthan.github.io/19/06/2019/rising-machine-intelligence-is-a-double-edged-sword/</link>
      <pubDate>Wed, 19 Jun 2019 00:00:00 +0000</pubDate>
      <guid>http://rahulmatthan.github.io/19/06/2019/rising-machine-intelligence-is-a-double-edged-sword/</guid>
      <description>&lt;p&gt;&lt;em&gt;Many prominent figures have warned of the dangers of uncontrolled AI development. Even so, skeptics argue that humans will always control machines. Modern AI lacks the ability to reason with &amp;ldquo;what if?&amp;rdquo; questions and counterfactual imagination, which are essential for human-like intelligence. Though machines are not yet at this level, I would urge caution in advancing AI towards these capabilities.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Machines can err but humans aren’t infallible either</title>
      <link>http://rahulmatthan.github.io/17/04/2019/machines-can-err-but-humans-arent-infallible-either/</link>
      <pubDate>Wed, 17 Apr 2019 00:00:00 +0000</pubDate>
      <guid>http://rahulmatthan.github.io/17/04/2019/machines-can-err-but-humans-arent-infallible-either/</guid>
      <description>&lt;p&gt;&lt;em&gt;It is important to incorporate human oversight into automated systems. Despite the efficiency of these systems, there is a need to balance human judgment with machine precision in critical decision-making processes.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>It’s time to frame rules for our artificial companions</title>
      <link>http://rahulmatthan.github.io/10/04/2019/its-time-to-frame-rules-for-our-artificial-companions/</link>
      <pubDate>Wed, 10 Apr 2019 00:00:00 +0000</pubDate>
      <guid>http://rahulmatthan.github.io/10/04/2019/its-time-to-frame-rules-for-our-artificial-companions/</guid>
      <description>&lt;p&gt;&lt;em&gt;The rapid advancement of smart home devices, with their increasing conversational intelligence, is leading to a future where touch-based inputs may become obsolete. These devices offer significant benefits, such as aiding the elderly and entertaining children, but also raise complex ethical and legal challenges. Issues like privacy, psychological impacts, especially on the young and elderly, and the handling of sensitive information, such as potential abuse reports, require careful consideration. The evolving nature of these interactions necessitates a new framework to address the multifaceted implications of conversational AI in our daily lives.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Ridding the judicial system of human subjectivity</title>
      <link>http://rahulmatthan.github.io/23/01/2019/ridding-the-judicial-system-of-human-subjectivity/</link>
      <pubDate>Wed, 23 Jan 2019 00:00:00 +0000</pubDate>
      <guid>http://rahulmatthan.github.io/23/01/2019/ridding-the-judicial-system-of-human-subjectivity/</guid>
      <description>&lt;p&gt;&lt;em&gt;Algorithmic sentencing, using machine learning to assess recidivism risk, has demonstrated consistent outcomes. But is not without flaws, sometimes reflecting human biases. Despite imperfections, I believe algorithms can introduce objectivity and be fine-tuned to reduce biases, making them more reliable than human judgment.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Using artificial intelligence more effectively</title>
      <link>http://rahulmatthan.github.io/14/11/2018/using-artificial-intelligence-more-effectively/</link>
      <pubDate>Wed, 14 Nov 2018 00:00:00 +0000</pubDate>
      <guid>http://rahulmatthan.github.io/14/11/2018/using-artificial-intelligence-more-effectively/</guid>
      <description>&lt;p&gt;&lt;em&gt;Despite its initial promise, AI solutions often fall short in the Indian legal context due to training on non-local data. A hybrid human-AI approach could build more responsive and effective systems.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Artificial Intelligence and the Law of the Horse</title>
      <link>http://rahulmatthan.github.io/09/05/2018/artificial-intelligence-and-the-law-of-the-horse/</link>
      <pubDate>Wed, 09 May 2018 00:00:00 +0000</pubDate>
      <guid>http://rahulmatthan.github.io/09/05/2018/artificial-intelligence-and-the-law-of-the-horse/</guid>
      <description>&lt;p&gt;&lt;em&gt;We should not create specific laws for new technologies when general legal principles will suffice. Recently, a government task force recommended applying existing legal provisions to AI, but this approach may not address AI&amp;rsquo;s unique aspects, such as personhood and liability in autonomous systems. The complexity of AI decisions, especially in impactful areas like criminal sentencing, necessitates a tailored regulatory framework that balances accuracy with explainability, challenging the notion of applying traditional legal principles to AI regulation.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Tabula Rasa</title>
      <link>http://rahulmatthan.github.io/01/11/2017/tabula-rasa/</link>
      <pubDate>Wed, 01 Nov 2017 00:00:00 +0000</pubDate>
      <guid>http://rahulmatthan.github.io/01/11/2017/tabula-rasa/</guid>
      <description>&lt;p&gt;&lt;em&gt;DeepMind has developed the world&amp;rsquo;s first tabula rasa algorithm, AlphaGo Zero, which learns from scratch without relying on human expertise or existing data. Unlike previous AI models, it learns through self-play, achieving mastery in the game of Go and uncovering novel strategies. This approach could revolutionize areas like genomic research and law, reducing concerns about privacy and human bias in algorithmic decision-making, and possibly leading to true artificial general intelligence.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Collaborative AI</title>
      <link>http://rahulmatthan.github.io/15/03/2017/collaborative-ai/</link>
      <pubDate>Wed, 15 Mar 2017 00:00:00 +0000</pubDate>
      <guid>http://rahulmatthan.github.io/15/03/2017/collaborative-ai/</guid>
      <description>&lt;p&gt;&lt;em&gt;Law firms struggle with partner compensation models, balancing profit and collaboration. The &amp;ldquo;eat-what-you-kill&amp;rdquo; model, based on individual revenue generation, can lead to competition and reduced cooperation. In contrast, the lockstep system, rewarding tenure over performance, may not fully incentivize productivity. Similar challenges exist in finance, where hedge funds guard proprietary data. Numerai, an AI firm, addresses this by using homomorphic encryption and a public platform, allowing data scientists to contribute to a meta-model, democratizing data without compromising confidentiality, and rewarding contributions with bitcoin. This innovative approach could inspire similar solutions in the legal industry.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>The Rise of the Machines</title>
      <link>http://rahulmatthan.github.io/02/11/2016/the-rise-of-the-machines/</link>
      <pubDate>Wed, 02 Nov 2016 00:00:00 +0000</pubDate>
      <guid>http://rahulmatthan.github.io/02/11/2016/the-rise-of-the-machines/</guid>
      <description>&lt;p&gt;&lt;em&gt;We should regulate autonomous weapons like we govern nuclear non-proliferation and climate change - through international consensus and not national policy. If we build machine intelligence that can decide who to kill this technology we will not be able to control whose hands this gets into.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
