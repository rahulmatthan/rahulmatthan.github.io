<!doctype html><html class=no-js lang=en><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><title>The challenge of detecting fake content - Ex Machina</title><script>(function(e,t){e[t]=e[t].replace("no-js","js")})(document.documentElement,"className")</script><meta name=description content><meta property="og:url" content="https://exmachina.in/21/11/2018/the-challenge-of-detecting-fake-content/"><meta property="og:site_name" content="Ex Machina"><meta property="og:title" content="The challenge of detecting fake content"><meta property="og:description" content="The information revolution has disrupted traditional media gatekeeping, leading to the unchecked spread of misinformation. The rise of deep fake technology, creating indistinguishable false content, exacerbates this issue. Governments are struggling to regulate, and potential solutions like immutable life logs raise privacy concerns."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2018-11-21T00:00:00+00:00"><meta property="article:modified_time" content="2018-11-21T00:00:00+00:00"><meta property="article:tag" content="Content Moderation"><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=dns-prefetch href=//fonts.googleapis.com><link rel=dns-prefetch href=//fonts.gstatic.com><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700"><link rel=stylesheet href=/css/style.css><link rel="shortcut icon" href=/favicon.ico></head><body class=body><div class="container container--outer"><header class=header><div class="container header__container"><div class="logo logo--mixed"><a class=logo__link href=/ title="Ex Machina" rel=home><div class="logo__item logo__imagebox"><img class=logo__img src=/images/exmachina.jpg></div><div class="logo__item logo__text"><div class=logo__title>Ex Machina</div><div class=logo__tagline>Law. Technology. Society.</div></div></a></div><nav class=menu><button class=menu__btn aria-haspopup=true aria-expanded=false tabindex=0>
<span class=menu__btn-title tabindex=-1>Menu</span></button><ul class=menu__list><li class=menu__item><a class=menu__link href=/index/><span class=menu__text>Index</span></a></li><li class=menu__item><a class=menu__link href=/topics/><span class=menu__text>Topics</span></a></li><li class=menu__item><a class=menu__link href=/books/><i class='fa fa-road'></i>
<span class=menu__text>Books</span></a></li><li class=menu__item><a class=menu__link href=/podcast/><i class='fa fa-road'></i>
<span class=menu__text>Podcast</span></a></li><li class=menu__item><a class=menu__link href=/about/><i class='fa fa-road'></i>
<span class=menu__text>About</span></a></li></ul></nav></div></header><div class="wrapper flex"><div class=primary><main class=main role=main><article class=post><header class=post__header><h1 class=post__title>The challenge of detecting fake content</h1><div class="post__meta meta"><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class=meta__text datetime=2018-11-21T00:00:00Z>November 21, 2018</time></div></div></header><div class="content post__content clearfix"><p><em>The information revolution has disrupted traditional media gatekeeping, leading to the unchecked spread of misinformation. The rise of deep fake technology, creating indistinguishable false content, exacerbates this issue. Governments are struggling to regulate, and potential solutions like immutable life logs raise privacy concerns.</em></p><p><em>This article was first published in The Mint. You can read the original at <a href=https://www.livemint.com/Opinion/rbLvtJE51jwOqE1nyayW8L/Opinion--The-challenge-of-detecting-fake-content.html>this link</a>.</em></p><hr><p>The information revolution has dramatically disrupted the news industry. Where we used to rely on media organizations to distribute news and other information, we now get our content from multiple sources too numerous to name. While this has given us access to a wider range of information, it has more than a few unintended consequences.</p><p>Media organisations have always been the gatekeepers of content. Regulated, as they are, by codes of ethical conduct and laws that impose penalties for putting out fake content, most media organizations have safeguards in place that ensure the veracity of the content they disseminate. This is why, even though it has for some time been possible to doctor images with impunity, we rarely see fake photographs in the news as journalists need to take care to ensure the accuracy of the news they report.</p><p>All of this is changing as we speak. Internet distribution has ensured that much of the content that reaches us does so without having first passed through traditional gatekeepers. Thanks to the cascade of information, we no longer have the bandwidth to verify the news we receive —it’s far easier to rely on what we are told than check even if the information we receive contradicts what we believe to be true. As a result, we believe without question much of what is passed on to us through social media. As more and more people recklessly share information, falsehoods are now accorded the same level of seriousness as facts.</p><p>At the same time, digital impersonation has improved to the point where it has become possible to generate entirely believable digital fakes in virtually any medium. Technologies like generative adversarial networks (GAN) use two neural networks—one to generate a fake image and the other to evaluate whether the first neural network succeeded in creating a suitable image. Working iteratively and in tandem, GAN technologies are capable of producing digital fakes that are virtually impossible to detect.</p><p>As a result, it is now possible for digital manipulators to put words into the mouths of public personalities and to generate, on the fly, video footage that seems completely genuine when in fact it is entirely made up. This technology is called deep fakes and while at present it is being primarily used by the porn industry to generate fake celebrity videos, it isn’t hard to imagine how these techniques, in the hands of the unscrupulous, could be used for extortion, defamation and false propaganda.</p><p>Both these phenomena are about to combine with devastating effect. We have already begun to see an increase in the frequency of information cascades that bypass gatekeepers of the truth and the effect that is having on our credibility. At the same time, new technologies capable of generating fiction that is indistinguishable from fact are becoming viable enough to be deployed widely.</p><p>Governments around the world are dealing with this problem by cracking down on the platforms through which content spreads. However, it is unclear to me what these platforms are expected to do. The really good deep fakes are indistinguishable from the truth and it will be virtually impossible for platforms, on their own, to distinguish truth from falsehood. Theoretically speaking, it should be possible to use the same neural network technologies that created deep fakes in the first place to develop forensic techniques that can detect fake content. However, most experts agree that this is easier said than done. All it will take to evade detection is for the deep fake technologies to be trained on exactly what it is that the new forensic techniques are detecting in order to be able to, very quickly, learn to evade these measures.</p><p>If our reality is capable of being so easily distorted, perhaps the answer lies in finding a non-repudiable way to establish the truth. One approach could be to create immutable life logs that prove, beyond the shadow of a doubt, what actually happened in a given person’s life from minute to minute. It should be possible to achieve this using technologies that are already around us—a combination of wearables, blockchain, cloud computing, remote sensing, etc. By combining inputs from multiple sources in a tamper-proof format, it should be possible establish a record of life that can rebut fake news.</p><p>To make all this more efficient, the immutable life record could be made accessible through APIs (application program interfaces) so that social medial services and other platforms that disseminate content can dynamically verify the content they carry against the true record of the life of a given person. Where the content matches the life log, platforms can continue to carry it. Where it does not, they will be able to prevent such content from portraying a false picture of an individual’s life.</p><p>The trouble with this approach is that it entails a considerable sacrifice of privacy. Comprehensive life logs, if compromised, could have a devastating effect on an individual’s personal life. That said, given the alternative, this might be a bargain that public personalities, who otherwise have a lot to lose, might feel worth making.</p><p>As we approach elections next year, we can expect a dramatic uptick in fake news as different political factions vie for our favour. We should be prepared for a good proportion of this to be based on deep fakes incapable of being distinguished from the truth. Now will be as good a time as any to test our defences against this menace.</p></div><footer class=post__footer><div class="post__tags tags clearfix"><svg class="tags__badge icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M32 19c0 1-1 2-1 2L21 31s-1 1-2 1-2-1-2-1L2 16c-1-1-1.4-2-1.4-2S0 12.5.0 11V3C0 1.5.8.8.8.8S1.5.0 3 0h8c1.5.0 3 .6 3 .6S15 1 16 2l15 15s1 1 1 2zM7 10a3 3 0 100-6 3 3 0 000 6z"/></svg><ul class=tags__list><li class=tags__item><a class="tags__link btn" href=/tags/content-moderation/ rel=tag>Content Moderation</a></li></ul></div></footer></article></main><div class="authorbox clearfix"><figure class=authorbox__avatar><img alt="Rahul Matthan avatar" src=/images/avatar.png class=avatar height=90 width=90></figure><div class=authorbox__header><span class=authorbox__name>About Rahul Matthan</span></div><div class=authorbox__description>Rahul Matthan is a lawyer who works at the intersection of law, technology and society.</div></div><nav class="pager flex"><div class="pager__item pager__item--prev"><a class=pager__link href=/14/11/2018/using-artificial-intelligence-more-effectively/ rel=prev><span class=pager__subtitle>«&#8201;Previous</span><p class=pager__title>Using artificial intelligence more effectively</p></a></div><div class="pager__item pager__item--next"><a class=pager__link href=/28/11/2018/the-use-of-technology-in-providing-healthcare/ rel=next><span class=pager__subtitle>Next&#8201;»</span><p class=pager__title>The use of technology in providing healthcare</p></a></div></nav></div><aside class=sidebar></aside></div><footer class=footer><div class="container footer__container flex"><div class=footer__copyright>&copy; 2025 Ex Machina.
<span class=footer__copyright-credits>Generated with <a href=https://gohugo.io/ rel="nofollow noopener" target=_blank>Hugo</a> and <a href=https://github.com/Vimux/Mainroad/ rel="nofollow noopener" target=_blank>Mainroad</a> theme.</span></div></div></footer></div><script async defer src=/js/menu.js></script></body></html>