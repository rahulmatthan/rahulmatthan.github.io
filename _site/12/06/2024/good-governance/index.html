<!doctype html><html class=no-js lang=en><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><title>Good Governance - Ex Machina</title><script>(function(e,t){e[t]=e[t].replace("no-js","js")})(document.documentElement,"className")</script><meta name=description content><meta property="og:url" content="https://exmachina.in/12/06/2024/good-governance/"><meta property="og:site_name" content="Ex Machina"><meta property="og:title" content="Good Governance"><meta property="og:description" content="Good governance often calls for placing the values of the organisation ahead of short term gains. This is particularly important in AI, where the demands of investor to make quick returns can very easily incentivise companies to play fast and loose with safety."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-06-12T00:00:00+00:00"><meta property="article:modified_time" content="2024-06-12T00:00:00+00:00"><meta property="article:tag" content="Artificial Intelligence"><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=dns-prefetch href=//fonts.googleapis.com><link rel=dns-prefetch href=//fonts.gstatic.com><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700"><link rel=stylesheet href=/css/style.css><link rel="shortcut icon" href=/favicon.ico></head><body class=body><div class="container container--outer"><header class=header><div class="container header__container"><div class="logo logo--mixed"><a class=logo__link href=/ title="Ex Machina" rel=home><div class="logo__item logo__imagebox"><img class=logo__img src=/images/exmachina.jpg></div><div class="logo__item logo__text"><div class=logo__title>Ex Machina</div><div class=logo__tagline>Law. Technology. Society.</div></div></a></div><nav class=menu><button class=menu__btn aria-haspopup=true aria-expanded=false tabindex=0>
<span class=menu__btn-title tabindex=-1>Menu</span></button><ul class=menu__list><li class=menu__item><a class=menu__link href=/index/><span class=menu__text>Index</span></a></li><li class=menu__item><a class=menu__link href=/topics/><span class=menu__text>Topics</span></a></li><li class=menu__item><a class=menu__link href=/books/><i class='fa fa-road'></i>
<span class=menu__text>Books</span></a></li><li class=menu__item><a class=menu__link href=/podcast/><i class='fa fa-road'></i>
<span class=menu__text>Podcast</span></a></li><li class=menu__item><a class=menu__link href=/about/><i class='fa fa-road'></i>
<span class=menu__text>About</span></a></li></ul></nav></div></header><div class="wrapper flex"><div class=primary><main class=main role=main><article class=post><header class=post__header><h1 class=post__title>Good Governance</h1><div class="post__meta meta"><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class=meta__text datetime=2024-06-12T00:00:00Z>June 12, 2024</time></div></div></header><div class="content post__content clearfix"><figure><img src=/images/good-governance.jpg width=auto></figure><p><em>Good governance often calls for placing the values of the organisation ahead of short term gains. This is particularly important in AI, where the demands of investor to make quick returns can very easily incentivise companies to play fast and loose with safety.</em></p><p><em>This is a link-enhanced version of an article that first appeared in the Mint. You can read the original <a href=https://www.livemint.com/opinion/online-views/openai-and-the-altman-ouster-attempt-corporate-governance-gone-wrong-11718042446667.html>here</a>.</em></p><hr><p>When OpenAI was founded in 2015, its <a href=https://openai.com/about/>primary objective</a> was to “advance digital intelligence in the way that is most likely to benefit humanity as a whole.” The path it chose to achieve this was to build large language models, a computationally intensive exercise that had only just become achievable at scale because of recent advances in modern chip design.</p><p>This, however, was going to require significant investment, and in order to raise these funds while staying true to its prime objective, OpenAI decided to put in place a <a href="https://www.theinformation.com/articles/you-can-separate-a-for-profit-company-from-a-nonprofit-i-helped-do-it?rc=rkdkqk&amp;shared=6bb363c6e82fcdfc">complex corporate structure</a> to separate ownership from control. Financial investors were made to invest in a for-profit company over whose governance they had no control. That would be determined by a different not-for-profit entity that was required to place human safety above all else, even if it was at the cost of profits or shareholder value.</p><p>In November 2023, the OpenAI board sacked Chief Executive Officer Sam Altman for, among other things, failing to provide the board with advance information on significant corporate developments, such as the launch of ChatGPT; at least <a href=https://www.theverge.com/2024/5/28/24166713/openai-helen-toner-explains-why-sam-altman-was-fired>one board member</a> later claimed that she had first got to know of its launch through social media. If this was true —if, in fact, Altman had not disclosed critical business information to the board before releasing it to the world—it seems clear that the board’s ability to prioritize human safety had been severely compromised. By sacking him, it would seem the board was doing exactly what it was supposed to.</p><h3 id=good-governance>Good Governance</h3><p>Good governance is about placing the core values of an organisation ahead of short-term commercial imperatives. While it might seem that the only reason businesses exist is to maximise profits, sustained profitability requires a performance culture built on a set of core values that are constantly and consistently enforced.</p><p>Through much of my professional career, I have been called upon to deal with many such instances—both as part of the management of my law firm as well as in the course of advising clients. Among the most difficult situations we’ve had to deal with are those that required us to take decisive action in order to uphold core organisation values. In more than a few instances, it involved taking action against high-performing individuals, or persons who either brought in significant revenue or controlled important client relationships. While considering the actions we had to take in order to uphold corporate values, we know we could suffer an immediate loss of revenue, while running the risk that some or all of the clients serviced by these individuals would leave with them. These are consequences no commercial organization wants to suffer. And yet, if that is what it takes to uphold the core values that define its culture, these are actions no firm can shy away from.</p><p>A well-governed organization will uphold its values even when it is not in its immediate commercial interest to do so. From experience, I can say that this is extraordinarily difficult to do in the moment. Concerns abound about the immediate commercial consequences of these actions and the impact on its reputation. It is only when the management recognizes that there is long-term value in preserving the culture of the organization that it will be able to hold true to its values despite the cost. Only organizations that consistently do this can truly evolve into institutions.</p><h3 id=reinstated>Reinstated</h3><p>Shortly after Altman was sacked as CEO of OpenAI, there was a widespread revolt in the company. Nearly <a href=https://www.forbes.com/sites/sanjitsinghdang/2023/11/24/sam-altman-being-reinstated-can-usher-in-an-openai-20-era/>800 employees</a> threatened to quit unless he was reinstated, pledging to follow him wherever he went. There was significant consternation in the industry over what this dismissal meant and how it would impact the future of AI. Eventually, all of OpenAI’s major investors had to step in to set things right.</p><p>OpenAI’s board had been tasked with ensuring that the company remained true to its core values even  if that came at a commercial cost. Its directors determined, for better or worse, that Altman remaining CEO was incompatible with these values, and so they ousted him from that role in the belief that doing so was aligned with their fiduciary obligation to uphold the core values of the organization.</p><p>Within a week of being sacked, Altman was <a href=https://x.com/OpenAI/status/1727206187077370115>re-instated as CEO</a>. The board that had terminated him was recast. Key members who were involved in his dismissal were removed and new members more aligned with his vision were appointed. <a href=https://www.wired.com/story/sam-altman-is-reinstated-to-openais-board/>Three months later</a>, Altman himself was back on the board of OpenAI.</p><h3 id=guardrails>Guardrails</h3><p>Now it is impossible for any outsider, much less someone on the other side of the planet, to opine on whether the board was right in doing what it did. What, however, is beyond doubt is that the guard-rails that OpenAI had put in place to ensure that no one—not even its CEO—could act in a manner inconsistent with its values, had failed. Not only was the board unable to hold Altman accountable, key members got sacked for trying.</p><p>There is every likelihood that OpenAI will continue to grow from strength to strength. However, there is no doubt that this growth will be driven by purely commercial incentives. Its prime objective is no longer to operate in the interests of humanity, but to protect the interests of its investors who are now effectively in control.</p><p>Whether OpenAI will, under these new circumstances, become the institution that it could have, only time will tell.</p></div><footer class=post__footer><div class="post__tags tags clearfix"><svg class="tags__badge icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M32 19c0 1-1 2-1 2L21 31s-1 1-2 1-2-1-2-1L2 16c-1-1-1.4-2-1.4-2S0 12.5.0 11V3C0 1.5.8.8.8.8S1.5.0 3 0h8c1.5.0 3 .6 3 .6S15 1 16 2l15 15s1 1 1 2zM7 10a3 3 0 100-6 3 3 0 000 6z"/></svg><ul class=tags__list><li class=tags__item><a class="tags__link btn" href=/tags/artificial-intelligence/ rel=tag>Artificial Intelligence</a></li></ul></div></footer></article></main><div class="authorbox clearfix"><figure class=authorbox__avatar><img alt="Rahul Matthan avatar" src=/images/avatar.png class=avatar height=90 width=90></figure><div class=authorbox__header><span class=authorbox__name>About Rahul Matthan</span></div><div class=authorbox__description>Rahul Matthan is a lawyer who works at the intersection of law, technology and society.</div></div><nav class="pager flex"><div class="pager__item pager__item--prev"><a class=pager__link href=/05/06/2024/diversity-through-ai/ rel=prev><span class=pager__subtitle>«&#8201;Previous</span><p class=pager__title>Diversity Through AI</p></a></div><div class="pager__item pager__item--next"><a class=pager__link href=/19/06/2024/ai-companions/ rel=next><span class=pager__subtitle>Next&#8201;»</span><p class=pager__title>AI Companions</p></a></div></nav></div><aside class=sidebar></aside></div><footer class=footer><div class="container footer__container flex"><div class=footer__copyright>&copy; 2025 Ex Machina.
<span class=footer__copyright-credits>Generated with <a href=https://gohugo.io/ rel="nofollow noopener" target=_blank>Hugo</a> and <a href=https://github.com/Vimux/Mainroad/ rel="nofollow noopener" target=_blank>Mainroad</a> theme.</span></div></div></footer></div><script async defer src=/js/menu.js></script></body></html>