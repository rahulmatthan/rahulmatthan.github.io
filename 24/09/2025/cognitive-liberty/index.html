<!doctype html><html class=no-js lang=en><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Cognitive Liberty - Ex Machina</title><script>(function(e,t){e[t]=e[t].replace("no-js","js")})(document.documentElement,"className")</script><meta name=description content><meta property="og:url" content="https://exmachina.in/24/09/2025/cognitive-liberty/"><meta property="og:site_name" content="Ex Machina"><meta property="og:title" content="Cognitive Liberty"><meta property="og:description" content="As the technology to collect neural information directly from our brains starts to become commercially viable, we need to think deeply about the social and ethical implications of this. Apart from just data protection we may need a broader articulation of cognitive liberty."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-09-24T00:00:00+00:00"><meta property="article:modified_time" content="2025-09-24T00:00:00+00:00"><meta property="article:tag" content="Privacy"><meta property="article:tag" content="Data Governance"><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=dns-prefetch href=//fonts.googleapis.com><link rel=dns-prefetch href=//fonts.gstatic.com><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700"><link rel=stylesheet href=/css/style.css><link rel="shortcut icon" href=/favicon.ico></head><body class=body><div class="container container--outer"><header class=header><div class="container header__container"><div class="logo logo--mixed"><a class=logo__link href=/ title="Ex Machina" rel=home><div class="logo__item logo__imagebox"><img class=logo__img src=/images/exmachina.jpg></div><div class="logo__item logo__text"><div class=logo__title>Ex Machina</div><div class=logo__tagline>Law. Technology. Society.</div></div></a></div><nav class=menu><button class=menu__btn aria-haspopup=true aria-expanded=false tabindex=0>
<span class=menu__btn-title tabindex=-1>Menu</span></button><ul class=menu__list><li class=menu__item><a class=menu__link href=/index/><span class=menu__text>Index</span></a></li><li class=menu__item><a class=menu__link href=/topics/><span class=menu__text>Topics</span></a></li><li class=menu__item><a class=menu__link href=/books/><i class='fa fa-road'></i>
<span class=menu__text>Books</span></a></li><li class=menu__item><a class=menu__link href=/podcast/><i class='fa fa-road'></i>
<span class=menu__text>Podcast</span></a></li><li class=menu__item><a class=menu__link href=/about/><i class='fa fa-road'></i>
<span class=menu__text>About</span></a></li></ul></nav></div></header><div class="wrapper flex"><div class=primary><main class=main role=main><article class=post><header class=post__header><h1 class=post__title>Cognitive Liberty</h1><div class="post__meta meta"><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0a14 14 0 110 28 1 1 0 010-28m0 3a3 3 0 100 22 3 3 0 000-22m1 4h-2v8.4l6.8 4.4L22 18l-6-3.8z"/></svg><time class=meta__text datetime=2025-09-24T00:00:00Z>September 24, 2025</time></div></div></header><div class="content post__content clearfix"><figure><img src=/images/cognitive-liberty.jpg width=auto></figure><p><em>As the technology to collect neural information directly from our brains starts to become commercially viable, we need to think deeply about the social and ethical implications of this. Apart from just data protection we may need a broader articulation of cognitive liberty.</em></p><p><em>This is a link-enhanced version of an article that first appeared in the Mint. You can read the original <a href=https://www.livemint.com/opinion/online-views/artificial-intelligence-data-protection-law-india-neuralink-ethics-cognitive-brain-privacy-ai-11758525049864.html>here</a>. If you would like to receive these articles in your inbox every week please consider subscribing by clicking on this <a href=https://paragraph.xyz/@exmachina>link</a>.</em></p><hr><p>As regular readers of Ex Machina know, I have been waiting more than a decade for India to pass a comprehensive data protection law. Despite recent statements by the government suggesting that rules under the 2023 Digital Personal Data Protection law are imminent, I have heard these promises so many times over the years that I have resigned myself to only believing it when I see it.</p><p>Meanwhile, technology has evolved at a blistering pace. When I first started working on a data protection law, I thought a notice and consent regime would be enough. I was convinced that so long as we offered individuals a meaningful way to exercise control over what was done with their data, they would have all the protection they needed. But with the advent of Big Data, it was clear that traditional notions of notice and consent were becoming increasingly meaningless. Not only was data being collected in so many different ways and by so many different entities that it had become impossible to keep track of, the ways in which this data was being used had become so complex that even the most digitally savvy among us were hard pressed to appreciate the consequences of our decisions.</p><p>Artificial intelligence (AI) has made things worse. Scant heed was paid to the data protection principles of prior consent and specific use when powerful AI systems were built. What’s more, since our interaction with AI systems takes place through chat interfaces, this has encouraged a level of intimacy that makes it easier for us to share more than we otherwise would, with little thought given to the consequences. But as bad as things are, they are about to get worse.</p><h3 id=neuro-data>Neuro Data</h3><p>In her book <a href=https://www.amazon.com/Battle-Your-Brain-Defending-Neurotechnology/dp/1250272955>The Battle for Your Brain</a>, Nita Farahany discusses the latest advances in neuro-technology and shows how close it is to widespread commercial availability. Affordable brain sensors can already collect data on our attention, fatigue, emotions and even our subconscious reactions directly from our brains. If we were worried about algorithms drawing inferences from our online behaviour, those fears pale in comparison with the harms that could result when insights about us are drawn directly from our brains.</p><p>It is China (not the Western world) that is at the vanguard of these technological developments. Railway drivers on the Beijing-Shanghai line (arguably the busiest high-speed link in the world) are already required to <a href=https://pmc.ncbi.nlm.nih.gov/articles/PMC7773904/>wear EEG devices</a> that collect real-time brain data in order to monitor their alertness levels. Factory workers in government-controlled facilities have to wear similar devices to monitor their productivity and current emotional states. Neural monitoring has already moved out of the realm of science fiction into everyday workspaces.</p><p>Very soon, these technologies will be deployed more widely around the world. It will likely start with high-risk job environments, where they will be used as a necessary measure to ensure safety. </p><p>But once the technology has proven itself, it will be promoted as a tool to improve productivity and efficiency. Soon, neural surveillance will become socially acceptable, both as a safety measure as well as a tool for improving our focus and managing emotions in a variety of different contexts.</p><p>When this happens, the technology will cross over into the wellness space. Around the world, EEG headsets are being advertised as brain-training devices that customers can use to modify their mental states. Companies like <a href=https://www.neuphony.com/>Neuphony</a> are already offering neurofeedback headbands in India, aimed at enhancing cognition and improving brain health. Non-invasive vagus nerve stimulation is being promoted as a way to reduce stress and improve sleep. Minimally invasive brain control interfaces are now being discussed in the context of augmenting cognition.</p><h3 id=cognitive-liberty>Cognitive Liberty</h3><p>But despite the many benefits that these devices have to offer, their adoption is likely to come at a high cost. Neural data is perhaps the most intimate form of personal data that is being processed today. The harms that could result if it is used maliciously—for coercion and manipulation or to shape attention and influence decisions—are likely to be far worse than anything we have seen so far.</p><p>These concerns have not gone unnoticed. Several states in the US have proposed new regulations to address the privacy concerns that arise out of the use of this technology—and the fact that users are simply incapable of deciding what neural information they should disclose, let alone understanding the extent to which what they have provided can be decoded or understood, currently or in the future. Chile has even enshrined neuro-rights in its constitution.</p><p>What is at stake, Farahany argues, is our cognitive liberty, a term she uses to encompass all the challenges of mental privacy and freedom of thought that these new technologies pose. Mental privacy extends to our subconscious reactions, emotions and thoughts—aspects of our personality that we have believed will remain deeply private. This curtails our freedom of thought as it exposes our inner beliefs and moral convictions in ways that affect our ability to engage with the full diversity of modern society.</p><p>India needs to think about what a cognitive liberty framework would look like. It needs to recognize brain data as fundamental to human autonomy, so we can regulate how it is collected and used. We need to ensure that India’s long awaited data protection regime addresses these concerns.</p></div><footer class=post__footer><div class="post__tags tags clearfix"><svg class="tags__badge icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M4 0h8s2 0 4 2l15 15s2 2 0 4L21 31s-2 2-4 0L2 16s-2-2-2-4V3s0-3 4-3m3 10a3 3 0 000-6 3 3 0 000 6"/></svg><ul class=tags__list><li class=tags__item><a class="tags__link btn" href=/tags/privacy/ rel=tag>privacy</a></li><li class=tags__item><a class="tags__link btn" href=/tags/data-governance/ rel=tag>data governance</a></li></ul></div></footer></article></main><nav class="pager flex"><div class="pager__item pager__item--prev"><a class=pager__link href=/17/09/2025/reclaim-the-rudder/ rel=prev><span class=pager__subtitle>«&#8201;Previous</span><p class=pager__title>Reclaim The Rudder</p></a></div><div class="pager__item pager__item--next"><a class=pager__link href=/01/10/2025/curiosity/ rel=next><span class=pager__subtitle>Next&#8201;»</span><p class=pager__title>Curiosity</p></a></div></nav></div><aside class=sidebar></aside></div><footer class=footer><div class="container footer__container flex"><div class=footer__copyright>&copy; 2025 Ex Machina.
<span class=footer__copyright-credits>Generated with <a href=https://gohugo.io/ rel="nofollow noopener" target=_blank>Hugo</a> and <a href=https://github.com/Vimux/Mainroad/ rel="nofollow noopener" target=_blank>Mainroad</a> theme.</span></div></div></footer></div><script async defer src=/js/menu.js></script></body></html>