<!doctype html><html class=no-js lang=en><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><title>How digital trust systems can guard against false data - Ex Machina</title><script>(function(e,t){e[t]=e[t].replace("no-js","js")})(document.documentElement,"className")</script><meta name=description content><meta property="og:url" content="https://exmachina.in/27/03/2019/how-digital-trust-systems-can-guard-against-false-data/"><meta property="og:site_name" content="Ex Machina"><meta property="og:title" content="How digital trust systems can guard against false data"><meta property="og:description" content="China’s social credit system monitors and scores citizens’ behaviors, rewarding or penalizing them accordingly. This system raises concerns about data accuracy and the impact of false information on individuals’ lives. As other countries might adopt similar systems, it’s crucial to ensure these algorithms are fair and continually reassess their trust evaluations to avoid unjust consequences."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2019-03-27T00:00:00+00:00"><meta property="article:modified_time" content="2019-03-27T00:00:00+00:00"><meta property="article:tag" content="Trust"><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=dns-prefetch href=//fonts.googleapis.com><link rel=dns-prefetch href=//fonts.gstatic.com><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700"><link rel=stylesheet href=/css/style.css><link rel="shortcut icon" href=/favicon.ico></head><body class=body><div class="container container--outer"><header class=header><div class="container header__container"><div class="logo logo--mixed"><a class=logo__link href=/ title="Ex Machina" rel=home><div class="logo__item logo__imagebox"><img class=logo__img src=/images/exmachina.jpg></div><div class="logo__item logo__text"><div class=logo__title>Ex Machina</div><div class=logo__tagline>Law. Technology. Society.</div></div></a></div><nav class=menu><button class=menu__btn aria-haspopup=true aria-expanded=false tabindex=0>
<span class=menu__btn-title tabindex=-1>Menu</span></button><ul class=menu__list><li class=menu__item><a class=menu__link href=/index/><span class=menu__text>Index</span></a></li><li class=menu__item><a class=menu__link href=/topics/><span class=menu__text>Topics</span></a></li><li class=menu__item><a class=menu__link href=/books/><i class='fa fa-road'></i>
<span class=menu__text>Books</span></a></li><li class=menu__item><a class=menu__link href=/podcast/><i class='fa fa-road'></i>
<span class=menu__text>Podcast</span></a></li><li class=menu__item><a class=menu__link href=/about/><i class='fa fa-road'></i>
<span class=menu__text>About</span></a></li></ul></nav></div></header><div class="wrapper flex"><div class=primary><main class=main role=main><article class=post><header class=post__header><h1 class=post__title>How digital trust systems can guard against false data</h1><div class="post__meta meta"><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0a14 14 0 110 28 1 1 0 010-28m0 3a3 3 0 100 22 3 3 0 000-22m1 4h-2v8.4l6.8 4.4L22 18l-6-3.8z"/></svg><time class=meta__text datetime=2019-03-27T00:00:00Z>March 27, 2019</time></div></div></header><div class="content post__content clearfix"><p><em>China&rsquo;s social credit system monitors and scores citizens&rsquo; behaviors, rewarding or penalizing them accordingly. This system raises concerns about data accuracy and the impact of false information on individuals&rsquo; lives. As other countries might adopt similar systems, it&rsquo;s crucial to ensure these algorithms are fair and continually reassess their trust evaluations to avoid unjust consequences.</em></p><p><em>This article was first published in The Mint. You can read the original at <a href=https://www.livemint.com/opinion/columns/opinion-how-digital-trust-systems-can-guard-against-false-data-1553623825836.html>this link</a>.</em></p><hr><p>In 1983, Tang Guoji graduated from ateachers’ college and applied for a job. Despite his more than adequate qualifications, he soon found that no work unit or graduate school in China was willing to employ him. He petitioned the government for a job and even filed complaints against the unfair treatment that was being meted out to him, but to no avail. He eventually became a freelance writer and earned some measure of success, but it wasn’t until 20 years later that he found out that he hadn’t been able to get a job after graduation because a college advisor whom he had rubbed the wrong way back in school had inserted a document into his dang’an that declared him mentally unstable.</p><p>The dang’an is a file that the Chinese government maintains on its urban residents containing details of all political, administrative and personal transgressions they commit. This file was integral to the Communist Party’s objective of social control and was designed to ensure that all citizens adhered to a set of expected societal norms and behaviour patterns. So central was the dang’an to life in communist China that anything entered in it was given the highest degree of credibility.</p><p>Today, people in China are less dependent on the Party for their jobs and, consequently, the importance of the dang’an has diminished. However, all this is set to change next year when the Chinese government’s new [[social credit]] system comes online. This all-seeing digital system uses the full breadth of modern internet technologies to detect adherence by individuals to the state’s vision of how a model citizen should behave. It has been designed to incentivize sincerity and trust-keeping, ensuring that citizens who conform to the ideal are rewarded with social and financial benefits, while those who do not are pilloried as shame-worthy and put on blacklists that limit their access to markets. In time, these digital frameworks will likely allow citizens to improve their own social credit scores by unfriending those in their social circle who do not conform to the ideal, creating the perfect mechanism of self policing.</p><p>The Chinese social credit system sounds like dang’an on steroids. It will give the Chinese government an unprecedented ability to nudge its citizens into behaving in the manner that the Party believes is appropriate, equipping the state with social levers, the likes of which no other ruler in history has ever had.</p><p>We have always used data to come to conclusions about the people around us—who we should trust and who we would be wise to steer clear of. As our interactions move increasingly online, more and more of the data that we use to evaluate trust is collected and processed through digital systems. It is inevitable that, as algorithms get better at analysing and processing this data, we will, as dystopian as it might sound, outsource our trust decision-making to them. If we already know that we are likely to start leaning on computers to help us make these decisions, it is crucial that we train these systems well.</p><p>We often base our decisions on first impressions, refusing to change our opinions of a person even if subsequent evidence indicates that our initial impressions were incorrect. If we hand off the responsibility of evaluating trust to machines, there is a risk that we will end up imbuing our digital decision making systems with the same shortcomings that colour our own decisions. When the conclusions that algorithms arrive at about the trustworthiness of a person are based on the scores they attribute to various types of human behaviour, it is likely that their final decisions will be coloured by inaccurate data. Just as the introduction of one incorrect document into Tang Guoji’s dang’an subjected him to a lifetime of suffering, computer systems that build trust profiles based on incrementally observed behaviours are defenceless against solitary instances of corrupted data that will colour the eventual recommendation.</p><p>On the other hand, there are people who allow their impressions to evolve over time, letting their determination of the trustworthiness of a person change based on each new element of information they receive. These are people who, though they might have distrusted someone based on their initial impressions of them, are more than willing to admit that they made a mistake once they have learnt a bit more about that person. If trust algorithms could be designed like this, to constantly question their trust assessments based on every new data point they receive, their final recommendations will be that much more nuanced. Algorithms built on this basis will be able to ensure that their initially inaccurate assumptions keep getting tested against subsequent inputs so that even if false data happens to creep into the system, it will not unduly affect the final assessment.</p><p>While China might be the first country to roll out social credit scores, as the world moves increasingly online, it is possible, likely even, that other countries will follow suit. When that happens, it is imperative that they use trust evaluation systems that have been designed to ensure that the malicious or accidental introduction of false data does not compromise its analysis.</p><p>If a manual paper file-based system could wreak such havoc on the life of an innocent individual, how much worse will it be when computational systems that we trust to operate with complete impartiality make the same mistakes?</p></div><footer class=post__footer><div class="post__tags tags clearfix"><svg class="tags__badge icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M4 0h8s2 0 4 2l15 15s2 2 0 4L21 31s-2 2-4 0L2 16s-2-2-2-4V3s0-3 4-3m3 10a3 3 0 000-6 3 3 0 000 6"/></svg><ul class=tags__list><li class=tags__item><a class="tags__link btn" href=/tags/trust/ rel=tag>Trust</a></li></ul></div></footer></article></main><div class="authorbox clearfix"><figure class=authorbox__avatar><img alt="Rahul Matthan avatar" src=/images/avatar.png class=avatar height=90 width=90></figure><div class=authorbox__header><span class=authorbox__name>About Rahul Matthan</span></div><div class=authorbox__description>Rahul Matthan is a lawyer who works at the intersection of law, technology and society.</div></div><nav class="pager flex"><div class="pager__item pager__item--prev"><a class=pager__link href=/20/03/2019/of-digital-competition-and-data-transfer-principles/ rel=prev><span class=pager__subtitle>«&#8201;Previous</span><p class=pager__title>Of digital competition and data transfer principles</p></a></div><div class="pager__item pager__item--next"><a class=pager__link href=/03/04/2019/get-set-for-a-blend-of-reality-and-its-augmented-version/ rel=next><span class=pager__subtitle>Next&#8201;»</span><p class=pager__title>Get set for a blend of reality and its augmented version</p></a></div></nav></div><aside class=sidebar></aside></div><footer class=footer><div class="container footer__container flex"><div class=footer__copyright>&copy; 2025 Ex Machina.
<span class=footer__copyright-credits>Generated with <a href=https://gohugo.io/ rel="nofollow noopener" target=_blank>Hugo</a> and <a href=https://github.com/Vimux/Mainroad/ rel="nofollow noopener" target=_blank>Mainroad</a> theme.</span></div></div></footer></div><script async defer src=/js/menu.js></script></body></html>