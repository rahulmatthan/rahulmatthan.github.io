<!doctype html><html class=no-js lang=en><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Engineering for Outcomes - Ex Machina</title><script>(function(e,t){e[t]=e[t].replace("no-js","js")})(document.documentElement,"className")</script><meta name=description content><meta property="og:url" content="https://exmachina.in/10/12/2025/engineering-for-outcomes/"><meta property="og:site_name" content="Ex Machina"><meta property="og:title" content="Engineering for Outcomes"><meta property="og:description" content="Our data regulations still prescribe processes that must be followed to bring about the scarcity we have long believed will ensure data protection. Rather than prescribing processes, we should focus on engineering for the outcomes we want to achieve."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-12-10T00:00:00+00:00"><meta property="article:modified_time" content="2025-12-10T00:00:00+00:00"><meta property="article:tag" content="Privacy"><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=dns-prefetch href=//fonts.googleapis.com><link rel=dns-prefetch href=//fonts.gstatic.com><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700"><link rel=stylesheet href=/css/style.css><link rel="shortcut icon" href=/favicon.ico></head><body class=body><div class="container container--outer"><header class=header><div class="container header__container"><div class="logo logo--mixed"><a class=logo__link href=/ title="Ex Machina" rel=home><div class="logo__item logo__imagebox"><img class=logo__img src=/images/exmachina.jpg></div><div class="logo__item logo__text"><div class=logo__title>Ex Machina</div><div class=logo__tagline>Law. Technology. Society.</div></div></a></div><nav class=menu><button class=menu__btn aria-haspopup=true aria-expanded=false tabindex=0>
<span class=menu__btn-title tabindex=-1>Menu</span></button><ul class=menu__list><li class=menu__item><a class=menu__link href=/index/><span class=menu__text>Index</span></a></li><li class=menu__item><a class=menu__link href=/topics/><span class=menu__text>Topics</span></a></li><li class=menu__item><a class=menu__link href=/books/><i class='fa fa-road'></i>
<span class=menu__text>Books</span></a></li><li class=menu__item><a class=menu__link href=/podcast/><i class='fa fa-road'></i>
<span class=menu__text>Podcast</span></a></li><li class=menu__item><a class=menu__link href=/about/><i class='fa fa-road'></i>
<span class=menu__text>About</span></a></li></ul></nav></div></header><div class="wrapper flex"><div class=primary><main class=main role=main><article class=post><header class=post__header><h1 class=post__title>Engineering for Outcomes</h1><div class="post__meta meta"><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0a14 14 0 110 28 1 1 0 010-28m0 3a3 3 0 100 22 3 3 0 000-22m1 4h-2v8.4l6.8 4.4L22 18l-6-3.8z"/></svg><time class=meta__text datetime=2025-12-10T00:00:00Z>December 10, 2025</time></div></div></header><div class="content post__content clearfix"><figure><img src=/images/engineering-for-outcomes.jpg width=auto></figure><p><em>Our data regulations still prescribe processes that must be followed to bring about the scarcity we have long believed will ensure data protection. Rather than prescribing processes, we should focus on engineering for the outcomes we want to achieve.</em></p><p><em>This article first appeared in the Mint. You can read the original <a href=https://www.livemint.com/opinion/online-views/india-privacy-law-outdated-ai-data-abundance-scarcity-artificial-intelligence-digital-personal-data-protection-11765199952737.html>here</a>. If you would like to receive these articles in your inbox every week please consider subscribing by clicking on this <a href=https://paragraph.xyz/@exmachina>link</a>.</em></p><hr><p>I have long argued that modern technologies can only be effective if governed by principle-based legislation. Prescriptive rules tend to be sclerotic, calcifying faster than the technology systems they seek to regulate. What we need instead are broad, durable principles that describe the outcomes we need, rather than the processes by which they are achieved. This ensures that the law’s objectives remain valid even after the technology it governs has evolved in a direction that no one could have anticipated.</p><p>The need for well-designed principles-based regulation is particularly acute in the era of artificial intelligence. If there is one thing that is predictable about these computational systems, it is that they will evolve in unpredictable directions. This suggests that the only way to effectively regulate them would be to define the principles according to which they must operate.</p><p>But what should those principles be?</p><h3 id=we-regulate-for-scarcity>We Regulate for Scarcity</h3><p>AI systems get better <a href=https://arxiv.org/abs/2001.08361>the more data they are trained on</a>. Their performance is directly correlated with the volume of their training data: the more data they ingest, the more useful they are. Today’s leading AI models have achieved their current levels of excellence only because they were created by processing volumes of data that would have been unimaginable even a decade ago. It is fair to say that our world today is defined by data abundance—and by computational models optimised to extract insights from such abundance.</p><p>However, the data governance regulations that apply to us ignore this fundamental feature of modern AI systems. They are still defined by ideas <a href=https://aspe.hhs.gov/reports/records-computers-rights-citizens>first developed in the 1970s</a>. Even today, data protection laws operate on the assumption that the best way to protect the privacy of individuals is to minimize the data available about them. This is why we have designed them to maximize data scarcity by ensuring that organizations collect as little data as possible and delete it as soon as practicable after it has been used. This is why the principles of data minimization and retention restriction remain the bedrock of privacy protection even today, nearly half a century after they were first devised.</p><p>To be clear, even though these restrictions have been in place for so long, they have failed in their intent to stem the flow of data or effectively curb its use. They are, as a result, little more than normative fiction: i.e. aspirational values experienced more in the breach than observance. Organizations have learnt to navigate around them <a href=https://harvardlawreview.org/print/vol-126/introduction-privacy-self-management-and-the-consent-dilemma/>by seeking consent</a> in terms so broad that once obtained, they have the legal authority to collect vast amounts of data, retain them for extended periods, transfer them through complex supply chains and freely use them for purposes that were not even contemplated when consent was sought. As a result, social media, e-commerce and a whole host of other online companies often know more about us today than we do ourselves.</p><h3 id=outcomes-not-processes>Outcomes Not Processes</h3><p>When it was enacted in 2023, India’s <a href=https://www.meity.gov.in/static/uploads/2024/06/2bf1f0e9f04e6fb4f8fef35e82c42aa5.pdf>Digital Personal Data Protection Act</a> was hailed as being a principles-based law—not just because of how radically it had been simplified in comparison with the more prescriptive drafts that preceded it, but also because of how much better it was when compared to global data protection frameworks elsewhere, such as the EU’s <a href=https://gdpr-info.eu/>General Data Protection Regulation</a>. It felt as if the time it had taken for us to finally come up with a new law was well worth the wait, as it had allowed us to learn from the mistakes that others had made and strike a balance between over-regulation and giving our enterprises the space they need to function.</p><p>Simplification, however, is necessary but not sufficient. Moving from prescriptive rules to a principles-based frame only works if the principles you select regulate outcomes, not processes. This is not what the Indian law has done. Instead of focusing on ‘what’ regulation needs to achieve, we have chosen to specify ‘how’ compliance must be implemented.</p><p>For instance, by requiring data minimisation and retention restriction, we force organisations to engineer for data scarcity as a means of ensuring personal privacy. Apart from how difficult this has proven to be in practice, in a world that increasingly stands to benefit from data abundance, a data protection law designed to create conditions of optimum scarcity risks denying us the valuable and socially beneficial outcomes that AI systems can offer.</p><h3 id=accountability>Accountability</h3><p>What we should have done instead is regulate outcomes. Rather than telling data fiduciaries how to process data, we should have told them that we will hold them <a href=https://exmachina.in/29/06/2016/the-accountability-framework/>accountable</a> for the harms that result from the actions they perform. Rather than specifying the steps they need to take, we should have designed the law to assess, in real time, exactly what their algorithms do, so that when harm occurs, it can be detected early enough to be mitigated.</p><p>Designing our regulatory frameworks in this manner will ensure that the governance framework we implement is outcome-oriented, technologically agnostic and remains relevant, notwithstanding the unpredictable directions in which our information systems may evolve. While the principles of data minimization and retention restriction offer comfort born of familiarity, they are hindering the development of governance frameworks that modern AI systems require.</p><p>In the age of data abundance, we cannot use rules designed for scarcity.</p></div><footer class=post__footer><div class="post__tags tags clearfix"><svg class="tags__badge icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M4 0h8s2 0 4 2l15 15s2 2 0 4L21 31s-2 2-4 0L2 16s-2-2-2-4V3s0-3 4-3m3 10a3 3 0 000-6 3 3 0 000 6"/></svg><ul class=tags__list><li class=tags__item><a class="tags__link btn" href=/tags/privacy/ rel=tag>privacy</a></li></ul></div></footer></article></main><nav class="pager flex"><div class="pager__item pager__item--prev"><a class=pager__link href=/03/12/2025/new-forensics/ rel=prev><span class=pager__subtitle>«&#8201;Previous</span><p class=pager__title>New Forensics</p></a></div><div class="pager__item pager__item--next"><a class=pager__link href=/17/12/2025/reverse-robin-hood/ rel=next><span class=pager__subtitle>Next&#8201;»</span><p class=pager__title>Reverse Robin Hood</p></a></div></nav></div><aside class=sidebar></aside></div><footer class=footer><div class="container footer__container flex"><div class=footer__copyright>&copy; 2025 Ex Machina.
<span class=footer__copyright-credits>Generated with <a href=https://gohugo.io/ rel="nofollow noopener" target=_blank>Hugo</a> and <a href=https://github.com/Vimux/Mainroad/ rel="nofollow noopener" target=_blank>Mainroad</a> theme.</span></div></div></footer></div><script async defer src=/js/menu.js></script></body></html>